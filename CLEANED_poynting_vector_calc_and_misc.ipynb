{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa81c523",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "pd.set_option('mode.chained_assignment', None)\n",
    "warnings.simplefilter(\"ignore\", category=RuntimeWarning)\n",
    "\n",
    "import random\n",
    "import os\n",
    "from juno_classes import *\n",
    "\n",
    "from scipy.integrate import trapz\n",
    "\n",
    "import matplotlib.colors\n",
    "from matplotlib.cm import ScalarMappable\n",
    "\n",
    "\n",
    "\n",
    "def extract_base_exponent_scientific(number):\n",
    "    # Calculate exponent with respect to base 10\n",
    "    exponent = int(np.log10(number))\n",
    "    base = number / (10 ** exponent)\n",
    "    return base, exponent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f68de36",
   "metadata": {},
   "outputs": [],
   "source": [
    "startOrbit = 8\n",
    "endOrbit = 52\n",
    "save_pickles = True\n",
    "\n",
    "for i in range(startOrbit, endOrbit+1):\n",
    "    print('grabbing mean mag orbit ' + str(i))\n",
    "    filename = '/home/mtfranciscovich/Juno-codes/jss_reduced_inbound_1s_means_4min_pickles/reduced_orbit_' +str(i) +'_4min_means_1s.pkl'\n",
    "    picklefile = open(filename,'rb')\n",
    "    orbit_means = pickle.load(picklefile)\n",
    "    \n",
    "    orbit_means_columns = list(orbit_means.columns)\n",
    "    \n",
    "    \n",
    "    fits_df_orbit = fits_data[orbit_means.index[0].isoformat(): orbit_means.index[-1].isoformat()]\n",
    "    \n",
    "    fits_bad_columns = list(['Tacc', '  \"R\"', ' \"LAT\"', 'ELON', ' \"LT\"',  'dr[MQ16]',\n",
    "       'dr[O2+]',  'dr[S+]',  'dr[S3+]',\n",
    "        '     \"dn\"', '  \"u\"', ' \"du\"',  '   \"dT\"',\n",
    "       'kappa', 'dkappa', ' \"uphi\"', 'duphi', '   \"ur\"', '  \"dur\"', '   \"uz\"',\n",
    "       '  \"duz\"', 'ISSUES1', 'ISSUES2', 'mode' ])\n",
    "    \n",
    "    \n",
    "    bad_columns = orbit_means_columns + fits_bad_columns\n",
    "    \n",
    "    \n",
    "    combined_df = pd.concat([orbit_means, fits_df_orbit], axis=1)\n",
    "    \n",
    "    combined_df = combined_df.drop(columns=bad_columns)\n",
    "    \n",
    "    print(combined_df)\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    " \n",
    "    print('Doing delta dens...')\n",
    "    delta_density_df = delta_densities(combined_df)\n",
    "    \n",
    "    if save_pickles:\n",
    "        delta_density_df.to_pickle('/home/mtfranciscovich/Juno-codes/fits_delta_densities/delta_dens_10min_orbit_' +str(i)+'.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dca644a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def delta_densities(fits_df,window_size = 10):\n",
    "    \n",
    "    amu = 1.67*10**-27\n",
    "    \n",
    "    m16 = 24*amu\n",
    "    mo2 = 16*amu\n",
    "    ms = 32*amu\n",
    "    ms3 = 32*amu\n",
    "    \n",
    "    n_raw = fits_df['      \"n\"']\n",
    "    m16_raw = fits_df['r[MQ16]']\n",
    "    mo_raw = fits_df['r[O2+]']\n",
    "    ms_raw = fits_df['r[S+]']\n",
    "    ms3_raw = fits_df['r[S3+]']\n",
    "\n",
    "    mean_density_data = pd.DataFrame({'MEAN_n': [], 'MEAN_mass': [], 'MEAN_density': [], 'MEAN_temperature': []})\n",
    "    finish_datetime = (fits_df.index[-1]\n",
    "    - timedelta(minutes=np.floor(window_size/2)))\n",
    "    for datetime_index in fits_df.index:\n",
    "        start_datetime = datetime_index\n",
    "        end_datetime = start_datetime + timedelta(minutes=window_size)\n",
    "        mean_datetime_index = pd.DatetimeIndex([\n",
    "            (start_datetime + timedelta(minutes=round(window_size/2))).isoformat()\n",
    "        ])\n",
    "        \n",
    "        check_array = n_raw[start_datetime.isoformat(): end_datetime.isoformat()].dropna()\n",
    "        \n",
    "        if len(check_array) < 4:\n",
    "            \n",
    "            continue\n",
    "        temp_mean_n = np.nanmean(n_raw[start_datetime.isoformat(): end_datetime.isoformat()])\n",
    "        temp_mean_m16 = np.nanmean(m16_raw[start_datetime.isoformat(): end_datetime.isoformat()])*m16\n",
    "        temp_mean_mo = np.nanmean(mo_raw[start_datetime.isoformat(): end_datetime.isoformat()])*mo2\n",
    "        temp_mean_ms = np.nanmean(ms_raw[start_datetime.isoformat(): end_datetime.isoformat()])*ms\n",
    "        temp_mean_ms3 = np.nanmean(ms3_raw[start_datetime.isoformat(): end_datetime.isoformat()])*ms3\n",
    "        \n",
    "        temp_mean_mass = temp_mean_m16+temp_mean_mo+temp_mean_ms+temp_mean_ms3\n",
    "        temp_mean_density = temp_mean_n*temp_mean_mass\n",
    "        \n",
    "        temp_mean_temperature = np.nanmean(fits_df['    \"T\"'][start_datetime.isoformat(): end_datetime.isoformat()])\n",
    "\n",
    "\n",
    "        mean_array_to_concat = pd.DataFrame(\n",
    "            {'MEAN_n': temp_mean_n,\n",
    "                'MEAN_mass': temp_mean_mass,\n",
    "                'MEAN_density': temp_mean_density,\n",
    "            'MEAN_temperature': temp_mean_temperature},\n",
    "            \n",
    "            index=mean_datetime_index)\n",
    "        mean_density_data = pd.concat([mean_density_data, mean_array_to_concat])\n",
    "        \n",
    "        if mean_datetime_index == finish_datetime:\n",
    "            break\n",
    "    # mean_mag_data and data_df are cut to align the time series of each\n",
    "    # mag_data loses half of the time_window in the front\n",
    "    # mean_mag_data loses half of the time window in the end\n",
    "    # The two dataframes are then concatenated into one for simplicity\n",
    "    #data_df = data_df.drop(data_df[: (data_df.index[0] +\n",
    "    #     timedelta(minutes=round(window_size / 2) - 1)\n",
    "    # ).isoformat()].index)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    fits_df = fits_df[mean_density_data.index[0].isoformat(): \n",
    "                                mean_density_data.index[-1].isoformat()]\n",
    "    fits_df = pd.concat([fits_df, mean_density_data], axis=1)\n",
    "    \n",
    "    print('density_mean_df made, looking at perts...')\n",
    "    del mean_density_data\n",
    "    \n",
    "\n",
    "    # The perturbation components of the mean field are found.\n",
    "    # The method used is described in Khurana & Kivelson 1989\n",
    "    \n",
    "    \n",
    "    #mean_mag_vecs = mag_data_df[['MEAN_BX', 'MEAN_BY', 'MEAN_BZ']]\n",
    "    #mean_mag_magnitude = np.sqrt((mean_mag_vecs**2).sum(axis=1))\n",
    "    \n",
    "    \n",
    "    \n",
    "    mean_density = fits_df['MEAN_density']\n",
    "    raw_density = n_raw* ( m16_raw*m16+mo_raw*mo2+ms_raw*ms + ms3_raw*ms3)\n",
    "\n",
    "    \n",
    "    perturbed_density = raw_density - mean_density\n",
    "\n",
    "    \n",
    "    perturbed_density_df = pd.DataFrame({'density_pert': perturbed_density})\n",
    "\n",
    "    \n",
    "\n",
    "            \n",
    "    data_df = pd.concat([fits_df, perturbed_density_df], axis=1)\n",
    "\n",
    "    return data_df\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ee1844",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_field_align_v_new(mag_data_df, v_data_df, window_size=10):\n",
    "    v_data_df = v_data_df.dropna()\n",
    "    \"\"\"Rotate magnetometer data into a mean-field-aligned coordinate system.\n",
    "        Using the methods described by Khurana & Kivelson[1989]\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    window_size : int, optional\n",
    "        The size of the window in minutes that is moved over data to average over.\n",
    "            This should be EVEN to ensure times of MFA and regular data line up.\n",
    "            The default is 24.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    None.\n",
    "\n",
    "    \"\"\"\n",
    "    # A windows of size 'window_size' in minutes is then moved along the data\n",
    "    # An average inside of the window is found for each entry\n",
    "    #print(self.data_df)\n",
    "    mean_v_data = pd.DataFrame({'MEAN_UX': [], 'MEAN_UY': [], 'MEAN_UZ': []})\n",
    "    finish_datetime = (v_data_df.index[-1]\n",
    "    - timedelta(minutes=np.floor(window_size/2)))\n",
    "    for datetime_index in v_data_df.index:\n",
    "        start_datetime = datetime_index\n",
    "        end_datetime = start_datetime + timedelta(minutes=window_size)\n",
    "        mean_datetime_index = pd.DatetimeIndex([\n",
    "            (start_datetime + timedelta(minutes=round(window_size/2))).isoformat()\n",
    "        ])\n",
    "        \n",
    "        check_array = v_data_df[start_datetime.isoformat(): end_datetime.isoformat()].dropna()\n",
    "        \n",
    "        if len(check_array) < 4:\n",
    "            \n",
    "            continue\n",
    "        \n",
    "        \n",
    "        temp_mean_x = np.nanmean(v_data_df[start_datetime.isoformat(): end_datetime.isoformat()].UX)\n",
    "        temp_mean_y = np.nanmean(v_data_df[start_datetime.isoformat(): end_datetime.isoformat()].UY)\n",
    "        temp_mean_z = np.nanmean(v_data_df[start_datetime.isoformat(): end_datetime.isoformat()].UZ)\n",
    "\n",
    "        mean_array_to_concat = pd.DataFrame(\n",
    "            {'MEAN_UX': temp_mean_x,\n",
    "                'MEAN_UY': temp_mean_y,\n",
    "                'MEAN_UZ': temp_mean_z}, index=mean_datetime_index)\n",
    "        mean_v_data = pd.concat([mean_v_data, mean_array_to_concat])\n",
    "        \n",
    "        if mean_datetime_index == finish_datetime:\n",
    "            break\n",
    "    # mean_mag_data and data_df are cut to align the time series of each\n",
    "    # mag_data loses half of the time_window in the front\n",
    "    # mean_mag_data loses half of the time window in the end\n",
    "    # The two dataframes are then concatenated into one for simplicity\n",
    "    #data_df = data_df.drop(data_df[: (data_df.index[0] +\n",
    "    #     timedelta(minutes=round(window_size / 2) - 1)\n",
    "    # ).isoformat()].index)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    v_data_df = v_data_df[mean_v_data.index[0].isoformat(): \n",
    "                                mean_v_data.index[-1].isoformat()]\n",
    "    v_data_df = pd.concat([v_data_df, mean_v_data], axis=1)\n",
    "    \n",
    "    print('v_mean_df made, looking at perts...')\n",
    "    del mean_v_data\n",
    "    \n",
    "\n",
    "    # The perturbation components of the mean field are found.\n",
    "    # The method used is described in Khurana & Kivelson 1989\n",
    "    \n",
    "    \n",
    "    #mean_mag_vecs = mag_data_df[['MEAN_BX', 'MEAN_BY', 'MEAN_BZ']]\n",
    "    #mean_mag_magnitude = np.sqrt((mean_mag_vecs**2).sum(axis=1))\n",
    "    \n",
    "    mean_mag_x = mag_data_df['MEAN_BX']\n",
    "    mean_mag_y = mag_data_df['MEAN_BY']\n",
    "    mean_mag_z = mag_data_df['MEAN_BZ']\n",
    "    mean_mag_magnitude = np.sqrt(mean_mag_x**2+mean_mag_y**2+mean_mag_z**2)\n",
    "    mean_mag_vecs = pd.DataFrame({'MEAN_BX': mean_mag_x, 'MEAN_BY': mean_mag_y,'MEAN_BZ': mean_mag_z}, index = mean_mag_x.index)\n",
    "    \n",
    "    mean_v_vecs = v_data_df[['MEAN_UX', 'MEAN_UY', 'MEAN_UZ']]\n",
    "    mean_v_magnitude = np.sqrt((mean_v_vecs**2).sum(axis=1))\n",
    "    \n",
    "    mean_ux = v_data_df['MEAN_UX']\n",
    "    mean_uy = v_data_df['MEAN_UY']\n",
    "    mean_uz = v_data_df['MEAN_UZ']\n",
    "    raw_ux = v_data_df['UX']\n",
    "    raw_uy = v_data_df['UY']\n",
    "    raw_uz = v_data_df['UZ']\n",
    "    \n",
    "    perturbed_ux = raw_ux - mean_ux\n",
    "    perturbed_uy = raw_uy - mean_uy\n",
    "    perturbed_uz = raw_uz - mean_uz\n",
    "    \n",
    "    perturbed_v_df = pd.DataFrame({'u_x_pert': perturbed_ux, 'u_y_pert': perturbed_uy, 'u_z_pert': perturbed_uz})\n",
    "    perturbed_v_df_perp = pd.DataFrame({'u_x_pert_perp': [], 'u_y_pert_perp': [], 'u_z_pert_perp': []})\n",
    "    perturbed_v_df_par = pd.DataFrame({'u_x_pert_par': [], 'u_y_pert_par': [], 'u_z_pert_par': []})\n",
    "    par_mag_v_df = pd.DataFrame({'u_pert_par': []})\n",
    "    \n",
    "    for i in range(len(perturbed_ux)):\n",
    "        new_df_index = pd.DatetimeIndex([v_data_df.index[i].isoformat()])\n",
    "        \n",
    "\n",
    "        \n",
    "        try: \n",
    "            x_for_hat = mean_mag_vecs['MEAN_BX'].loc[new_df_index]\n",
    "            y_for_hat = mean_mag_vecs['MEAN_BY'].loc[new_df_index]\n",
    "            z_for_hat = mean_mag_vecs['MEAN_BZ'].loc[new_df_index]\n",
    "\n",
    "            parallel_mag_hat = (np.asarray([x_for_hat,y_for_hat,z_for_hat]) / mean_mag_magnitude.loc[new_df_index][0])\n",
    "\n",
    "            \n",
    "            perturbed_vparallel_to_mag = np.dot((perturbed_v_df.iloc[i].to_numpy()), parallel_mag_hat)\n",
    "            perturbed_vparallel_to_mag_vector = np.asarray(perturbed_vparallel_to_mag*parallel_mag_hat)\n",
    "            perturbed_par_ux = perturbed_vparallel_to_mag_vector[0]\n",
    "            perturbed_par_uy = perturbed_vparallel_to_mag_vector[1]\n",
    "            perturbed_par_uz = perturbed_vparallel_to_mag_vector[2]\n",
    "            perturbed_perp_ux = perturbed_v_df.iloc[i]['u_x_pert'] - perturbed_par_ux\n",
    "            perturbed_perp_uy = perturbed_v_df.iloc[i]['u_y_pert'] - perturbed_par_uy\n",
    "            perturbed_perp_uz = perturbed_v_df.iloc[i]['u_z_pert'] - perturbed_par_uz\n",
    "            \n",
    "            \n",
    "            perturbed_v_df_perp = pd.concat([perturbed_v_df_perp,pd.DataFrame({'u_x_pert_perp': perturbed_perp_ux, 'u_y_pert_perp': perturbed_perp_uy, 'u_z_pert_perp': perturbed_perp_uz},\n",
    "                                    index=new_df_index)])\n",
    "\n",
    "            perturbed_v_df_par = pd.concat([perturbed_v_df_par, pd.DataFrame({'u_x_pert_par': perturbed_par_ux, 'u_y_pert_par': perturbed_par_uy, 'u_z_pert_par': perturbed_par_uz},\n",
    "                            index=new_df_index) ])\n",
    "            \n",
    "            par_mag_v_df = pd.concat([par_mag_v_df,         pd.DataFrame({'u_pert_par': perturbed_vparallel_to_mag},\n",
    "                            index=new_df_index)])\n",
    "        except:\n",
    "            continue\n",
    "            \n",
    "    data_df = pd.concat([v_data_df, perturbed_v_df_perp], axis=1)\n",
    "    data_df  = pd.concat([data_df, perturbed_v_df_par], axis=1)\n",
    "    data_df = pd.concat([data_df, par_mag_v_df], axis = 1)\n",
    "    return data_df\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a2d581d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fits_data = pd.read_csv('/data/juno_spacecraft/data/FWD_FITS/JADE-I_forward_model_ion_v1/JADE-I_forward_model_ion_all_v1.csv', delimiter= ',')\n",
    "def convert_datetime(datetime_str):\n",
    "    # Remove the microseconds part\n",
    "    datetime_str_cleaned = datetime_str.split('.')[0]\n",
    "    # Convert to pandas datetime object\n",
    "    date_time = pd.to_datetime(datetime_str_cleaned, format='%Y-%jT%H:%M:%S')\n",
    "    # Format to the desired output\n",
    "    return pd.to_datetime(date_time.strftime('%Y-%m-%dT%H:%M:%S'))\n",
    "\n",
    "fits_data['DATETIME'] = fits_data['                \"UTC\"'].apply(convert_datetime)\n",
    "fits_data = fits_data.drop(columns='                \"UTC\"')\n",
    "\n",
    "fits_data = fits_data.set_index('DATETIME', drop=True)\n",
    "\n",
    "ur = fits_data['   \"ur\"']\n",
    "uphi = fits_data[' \"uphi\"']\n",
    "uz = fits_data['   \"uz\"']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "834148b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For above to work correctly, ie match up, need to make a df that has all\n",
    "#of the date times of an orbit, like the og mag mean arrays\n",
    "\n",
    "\n",
    "startOrbit = 26\n",
    "endOrbit = 54\n",
    "save_pickles = False\n",
    "\n",
    "for i in range(startOrbit, endOrbit+1):\n",
    "    orbit = i\n",
    "    print('grabbing orbit ' + str(i))\n",
    "    filename = '/home/mtfranciscovich/Juno-codes/reduced_inbound_1s_pickles_unit_z_mag/reduced_orbit_' +str(orbit)+'_1s.pkl'\n",
    "    picklefile = open(filename,'rb')\n",
    "    rawdata = pickle.load(picklefile)\n",
    "    \n",
    "    x = rawdata['X_JSS']\n",
    "    y = rawdata['Y_JSS']\n",
    "    z = rawdata['Z_JSS']\n",
    "    \n",
    "    Rj_km = 7.14e4\n",
    "    \n",
    "    \n",
    "\n",
    "    phi = np.arctan2(y,x)\n",
    "\n",
    "    ux = ur*np.cos(phi) - uphi*np.sin(phi)\n",
    "    uy = ur*np.sin(phi) + uphi*np.cos(phi)\n",
    "\n",
    "    orbitStartTime = x.index[0]\n",
    "    orbitEndTime = x.index[-1]\n",
    "\n",
    "    fits_data_cart_orbit = pd.DataFrame({'UX': ux[orbitStartTime:orbitEndTime], 'UY': uy[orbitStartTime:orbitEndTime], 'UZ': uz[orbitStartTime:orbitEndTime]})\n",
    "    fits_data_cart_orbit['Z_MAG'] = rawdata['Z_MAG']\n",
    "    fits_data_cart_orbit['R'] = np.sqrt(rawdata['X_JSS']**2 + rawdata['Y_JSS']**2)/Rj_km\n",
    "    if save_pickles:\n",
    "        fits_data_cart_orbit.to_pickle('/home/mtfranciscovich/Juno-codes/fits_u_cart_pickles_updated/u_cart_orbit_' +str(i)+'.pkl')\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b40cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "startOrbit = 35\n",
    "endOrbit = 54\n",
    "save_pickles = True\n",
    "mu_0 = np.pi*4e-7\n",
    "gamma = 5/3\n",
    "k_B = 1.38e-23\n",
    "\n",
    "#window_size = 30\n",
    "\n",
    "for i in range(startOrbit, endOrbit+1):\n",
    "    print('grabbing mean mag orbit ' + str(i))\n",
    "    filename = '/home/mtfranciscovich/Juno-codes/jss_reduced_inbound_1s_means_4min_pickles/reduced_orbit_' +str(i) +'_4min_means_1s.pkl'\n",
    "    picklefile = open(filename,'rb')\n",
    "    mean_mag_data = pickle.load(picklefile)\n",
    "    \n",
    "    orbit_means = mean_mag_data\n",
    "    \n",
    "    \n",
    "    print('grabbing mean v orbit ' + str(i))\n",
    "    filename = '/home/mtfranciscovich/Juno-codes/test_fits_u_cart_means_4min/u_cart_means_4min_orbit_' +str(i) +'.pkl'\n",
    "    picklefile = open(filename,'rb')\n",
    "    mean_v_data = pickle.load(picklefile)\n",
    "    \n",
    "    all_dates = orbit_means.index.union(fits_data.index)\n",
    "\n",
    "    reindexed_orbit_means = orbit_means.reindex(all_dates)\n",
    "    reindexed_fits_data = fits_data.reindex(all_dates)\n",
    "\n",
    "    combined_current = reindexed_orbit_means.combine_first(reindexed_fits_data)\n",
    "    \n",
    "    \n",
    "\n",
    "    beginning_of_orbit_data = orbit_means.index[0]\n",
    "    end_of_orbit_data = orbit_means.index[-1]\n",
    "\n",
    "\n",
    "    combined_updated_for_orbit = combined_current[beginning_of_orbit_data:end_of_orbit_data]\n",
    "\n",
    "\n",
    "    print('grabbing delta densities')\n",
    "    filename = '/home/mtfranciscovich/Juno-codes/code/delta_density_df.pkl'\n",
    "    picklefile = open(filename,'rb')\n",
    "    delta_density_data = pickle.load(picklefile)\n",
    "    \n",
    "    print('Calculating ratios...')\n",
    "    \n",
    "\n",
    "    ux_pert_perp = mean_v_data['u_x_pert_perp']*1e3\n",
    "    uy_pert_perp = mean_v_data['u_y_pert_perp']*1e3\n",
    "    uz_pert_perp = mean_v_data['u_z_pert_perp']*1e3\n",
    "    \n",
    "    delta_v_perp_mag = np.sqrt(ux_pert_perp**2 + uy_pert_perp**2 + uz_pert_perp**2)\n",
    "    \n",
    "\n",
    "    \n",
    "    Bx_total = mean_mag_data['MEAN_BX']*(10**-9)\n",
    "    By_total = mean_mag_data['MEAN_BY']*(10**-9)\n",
    "    Bz_total = mean_mag_data['MEAN_BZ']*(10**-9)\n",
    "    \n",
    "    Bx_pert_perp = mean_mag_data['B_x_pert_perp']*(10**-9)\n",
    "    By_pert_perp = mean_mag_data['B_y_pert_perp']*(10**-9)\n",
    "    Bz_pert_perp = mean_mag_data['B_z_pert_perp']*(10**-9)\n",
    "    \n",
    "    B_pert_perp_mag = np.sqrt(Bx_pert_perp**2 + By_pert_perp**2 + Bz_pert_perp**2)\n",
    "    \n",
    "    Bx_pert_par = mean_mag_data['B_x_pert_par']*(10**-9)\n",
    "    By_pert_par = mean_mag_data['B_y_pert_par']*(10**-9)\n",
    "    Bz_pert_par = mean_mag_data['B_z_pert_par']*(10**-9)\n",
    "    \n",
    "    B_pert_par_mag = np.sqrt(Bx_pert_par**2 + By_pert_par**2 + Bz_pert_par**2)\n",
    "    \n",
    "    mean_vecs = mean_mag_data[['MEAN_BX','MEAN_BY','MEAN_BZ']]\n",
    "    mean_magnitude  = np.sqrt(Bx_total**2 + By_total**2 + Bz_total**2)\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "    mean_density = delta_density_data['MEAN_density']*1e6\n",
    "    mean_mass = delta_density_data['MEAN_mass']\n",
    "    \n",
    "    mean_temp = delta_density_data['MEAN_temperature']\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    v_Alfven= (mean_magnitude)/np.sqrt(mu_0*mean_density) #does v_alfven need to be a vector quantity?]\\\n",
    "      \n",
    "        \n",
    "    v_S_squared =    gamma*mean_temp*11606*k_B/mean_mass\n",
    "    \n",
    "    delta_density = delta_density_data['density_pert']*1e6\n",
    "    \n",
    "    delta_density = delta_density + v_Alfven*0\n",
    "    v_S_squared = v_S_squared + v_Alfven*0\n",
    "    \n",
    "    mean_density = mean_density + v_Alfven*0\n",
    "    \n",
    "    delta_v_perp_mag = delta_v_perp_mag + v_Alfven*0+mean_magnitude*0+mean_density*0\n",
    "    \n",
    "    compression_df = pd.DataFrame({'delta_density':delta_density, 'v_Alfven':v_Alfven, 'v_S':np.sqrt(v_S_squared), 'delta_v_perp_mag':delta_v_perp_mag, 'MEAN_density':mean_density, 'B_pert_perp_mag':B_pert_perp_mag, 'B_pert_par_mag':B_pert_par_mag, 'MEAN_B':mean_magnitude})\n",
    "    \n",
    " \n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    print('Combine with z_mag  and R array ...')\n",
    "    \n",
    "    filename = '/home/mtfranciscovich/Juno-codes/reduced_inbound_1s_pickles/reduced_orbit_' +str(i) +'_1s.pkl'\n",
    "    picklefile = open(filename,'rb')\n",
    "    mag_data_mag_frame = pickle.load(picklefile)\n",
    "    z_mag_info = mag_data_mag_frame['Z_MAG']\n",
    "    R_info = mag_data_mag_frame['R']\n",
    "    \n",
    "    compression_df['Z_MAG'] = z_mag_info\n",
    "    compression_df['R'] = R_info\n",
    "    \n",
    "\n",
    "    if save_pickles:\n",
    "        compression_df.to_pickle('/home/mtfranciscovich/Juno-codes/compression_dfs_by_orbit/compression_df_orbit_' + str(i) + '.pkl')\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca0c06af",
   "metadata": {},
   "outputs": [],
   "source": [
    "startOrbit = 36\n",
    "endOrbit = 54\n",
    "save_pickles = True\n",
    "mu_0 = np.pi*4e-7\n",
    "\n",
    "window_size = 30\n",
    "\n",
    "print('grabbing mean density')\n",
    "filename = '/home/mtfranciscovich/Juno-codes/code/delta_density_df_2.pkl'\n",
    "picklefile = open(filename,'rb')\n",
    "mean_density_data = pickle.load(picklefile)\n",
    "\n",
    "for i in range(startOrbit, endOrbit+1):\n",
    "    if i ==49:\n",
    "        continue\n",
    "    print('grabbing mean mag orbit ' + str(i))\n",
    "    #filename = '/home/mtfranciscovich/Juno-codes/jss_downsampled_mag_pickles_10min/reduced_orbit_' +str(i) +'_10min_means_1s.pkl'\n",
    "    filename = '/home/mtfranciscovich/Juno-codes/means_10min_reduced_inbound_1s_pickles_unit_z_mag_jss_downsampled/reduced_orbit_'+str(i)+'_1s.pkl'\n",
    "    picklefile = open(filename,'rb')\n",
    "    mean_mag_data = pickle.load(picklefile)\n",
    "    \n",
    "    orbit_means = mean_mag_data\n",
    "    \n",
    "    print('grabbing total mag orbit ' + str(i))\n",
    "    filename = '/home/mtfranciscovich/Juno-codes/reduced_inbound_1s_pickles_unit_z_mag/reduced_orbit_'+str(i)+'_1s.pkl'\n",
    "    picklefile = open(filename,'rb')\n",
    "    total_mag_data = pickle.load(picklefile)\n",
    "    \n",
    "    \n",
    "    #filename = '/home/mtfranciscovich/Juno-codes/reduced_inbound_1s_means_4min_pickles/reduced_orbit_' + str(i) + '_4min_means_1s.pkl'\n",
    "    \n",
    "    #picklefile = open(filename,'rb')\n",
    "    #mean_mag_data_mag_coord = pickle.load(picklefile)\n",
    "    \n",
    "    #orbit_means_mag_cord = mean_mag_data_mag_coord\n",
    "    \n",
    "    \n",
    "    \n",
    "    print('grabbing mean v orbit ' + str(i))\n",
    "    #filename = '/home/mtfranciscovich/Juno-codes/test_fits_u_cart_means_4min/u_cart_means_4min_orbit_' +str(i) +'.pkl'\n",
    "    filename = '/home/mtfranciscovich/Juno-codes/updated_fits_u_cart_means_10min/u_cart_means_10min_orbit_' +str(i)+'.pkl'\n",
    "    picklefile = open(filename,'rb')\n",
    "    mean_v_data = pickle.load(picklefile)\n",
    "    \n",
    "    print('grabbing total v orbit ' + str(i))\n",
    "    filename = '/home/mtfranciscovich/Juno-codes/fits_u_cart_pickles_updated/u_cart_orbit_'+str(i)+'.pkl'\n",
    "    picklefile = open(filename,'rb')\n",
    "    total_v_data = pickle.load(picklefile)\n",
    "    \n",
    "\n",
    " \n",
    "    \n",
    "    all_dates = orbit_means.index.union(fits_data.index)\n",
    "\n",
    "    reindexed_orbit_means = orbit_means.reindex(all_dates)\n",
    "    reindexed_fits_data = fits_data.reindex(all_dates)\n",
    "\n",
    "    combined_current = reindexed_orbit_means.combine_first(reindexed_fits_data)\n",
    "    \n",
    "    \n",
    "\n",
    "    beginning_of_orbit_data = orbit_means.index[0]\n",
    "    end_of_orbit_data = orbit_means.index[-1]\n",
    "    \n",
    "    \n",
    "    print('cleaning mean density')\n",
    "    \n",
    "    delta_density_data = mean_density_data[beginning_of_orbit_data:end_of_orbit_data]\n",
    "\n",
    "\n",
    "    combined_updated_for_orbit = combined_current[beginning_of_orbit_data:end_of_orbit_data]\n",
    "\n",
    "    \n",
    "    print('Calculating dot prod and helicity...')\n",
    "    \n",
    "\n",
    "    ux_pert_perp = mean_v_data['u_x_pert_perp']*1e3\n",
    "    uy_pert_perp = mean_v_data['u_y_pert_perp']*1e3\n",
    "    uz_pert_perp = mean_v_data['u_z_pert_perp']*1e3\n",
    "    \n",
    "    Bx_pert_perp = mean_mag_data['B_x_pert_perp']*(10**-9)\n",
    "    By_pert_perp = mean_mag_data['B_y_pert_perp']*(10**-9)\n",
    "    Bz_pert_perp = mean_mag_data['B_z_pert_perp']*(10**-9)\n",
    "    \n",
    "    Bx_total = mean_mag_data['MEAN_BX']*(10**-9)\n",
    "    By_total = mean_mag_data['MEAN_BY']*(10**-9)\n",
    "    Bz_total = mean_mag_data['MEAN_BZ']*(10**-9)\n",
    "    \n",
    "    \n",
    "    #Bx_mag_coord = mean_mag_data_mag_coord['MEAN_BX']*(10**-9)\n",
    "    #By_mag_coord = mean_mag_data_mag_coord['MEAN_BY']*(10**-9)\n",
    "    #Bz_mag_coord = mean_mag_data_mag_coord['MEAN_BZ']*(10**-9)\n",
    "    \n",
    "    mean_magnitude_mag_coord = np.sqrt(Bx_total**2+By_total**2+Bz_total**2)\n",
    "    \n",
    "    unitz_x = total_mag_data['UNITZ_X']\n",
    "    unitz_y = total_mag_data['UNITZ_Y']\n",
    "    unitz_z = total_mag_data['UNITZ_Z']\n",
    " \n",
    "    \n",
    "    cos_theta = (Bx_total*unitz_x+By_total*unitz_y+Bz_total*unitz_z)/mean_magnitude_mag_coord\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    mean_vecs = mean_mag_data[['MEAN_BX','MEAN_BY','MEAN_BZ']]\n",
    "    mean_magnitude  = np.sqrt(Bx_total**2 + By_total**2 + Bz_total**2)\n",
    "    \n",
    "    #B0 = np.dot((mean_vecs).to_numpy(), parallel_hat)\n",
    "    \n",
    "    B_tot_mag = np.sqrt(Bx_total**2 + By_total**2 + Bz_total**2)\n",
    "    \n",
    "    #test = Bx_total/B_tot_mag\n",
    "    \n",
    "    mean_density = delta_density_data['MEAN_density']*1e6\n",
    "    mean_mass = delta_density_data['MEAN_mass']\n",
    "    \n",
    "    mean_temp = delta_density_data['MEAN_temperature']\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    v_Alfven= (mean_magnitude)/np.sqrt(mu_0*mean_density)\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    n = combined_updated_for_orbit['      \"n\"'] \n",
    "    m16 = combined_updated_for_orbit['r[MQ16]']\n",
    "    mo = combined_updated_for_orbit['r[O2+]']\n",
    "    ms = combined_updated_for_orbit['r[S+]']\n",
    "    ms3 = combined_updated_for_orbit['r[S3+]']\n",
    "    \n",
    "    m16_factor = 5.32*10**-26 + 2.65*10**-26\n",
    "    mo2_factor = 5.31*10**-26\n",
    "    ms_factor = 5.32*10**-26\n",
    "    ms3_factor = 5.32*10**-26\n",
    "    \n",
    "\n",
    "    m = m16*m16_factor + mo*mo2_factor +ms*ms_factor+ms3*ms3_factor\n",
    "\n",
    "    density = m * n*1e6\n",
    "    \n",
    "    '''\n",
    "\n",
    "    '''\n",
    "    v_Alfven_x = (Bx_total)/np.sqrt(mu_0*density) #does v_alfven need to be a vector quantity?\n",
    "    v_Alfven_y = (By_total)/np.sqrt(mu_0*density) #does v_alfven need to be a vector quantity?\n",
    "    v_Alfven_z = (Bz_total)/np.sqrt(mu_0*density) #does v_alfven need to be a vector quantity?\n",
    "    '''\n",
    "    \n",
    "    Bx_pert_perp_norm = Bx_pert_perp/mean_magnitude\n",
    "    By_pert_perp_norm = By_pert_perp/mean_magnitude\n",
    "    Bz_pert_perp_norm = Bz_pert_perp/mean_magnitude\n",
    "    \n",
    "    ux_pert_perp_norm = ux_pert_perp/v_Alfven\n",
    "    uy_pert_perp_norm = uy_pert_perp/v_Alfven\n",
    "    uz_pert_perp_norm = uz_pert_perp/v_Alfven\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    dot_prod_for_calc = ux_pert_perp*Bx_pert_perp + uy_pert_perp*By_pert_perp + uz_pert_perp*Bz_pert_perp\n",
    "    \n",
    "    \n",
    "    factor = np.sqrt(Bx_total**2 + By_total**2 + Bz_total**2)*(1/mu_0)\n",
    "    \n",
    "    delta_dot_prod = (-1)*(dot_prod_for_calc)*(factor)\n",
    "    \n",
    "    Helicity = dot_prod_for_calc/2\n",
    "    \n",
    "    norm_Helicity_num = ux_pert_perp_norm*Bx_pert_perp_norm + uy_pert_perp_norm*By_pert_perp_norm + uz_pert_perp_norm*Bz_pert_perp_norm\n",
    "\n",
    "    \n",
    "    \n",
    "    delta_vperp_squared_norm = ux_pert_perp_norm**2+uy_pert_perp_norm**2+uz_pert_perp_norm**2\n",
    "    delta_Bperp_squared_norm = Bx_pert_perp_norm**2+By_pert_perp_norm**2+Bz_pert_perp_norm**2\n",
    "    \n",
    "    delta_energy_norm = 0.5*(delta_vperp_squared_norm+delta_Bperp_squared_norm)\n",
    "    \n",
    "    norm_Helicity = norm_Helicity_num/delta_energy_norm\n",
    "    \n",
    "    \n",
    "    residual_energy_num = delta_vperp_squared_norm - delta_Bperp_squared_norm\n",
    "    \n",
    "    residual_energy_denom = delta_vperp_squared_norm + delta_Bperp_squared_norm\n",
    "    \n",
    "    residual_energy_Norm = residual_energy_num/residual_energy_denom\n",
    "    \n",
    "    delta_vperp_magnitude = np.sqrt(ux_pert_perp**2+uy_pert_perp**2+uz_pert_perp**2)\n",
    "    \n",
    "    delta_Bperp_magnitude = np.sqrt(Bx_pert_perp**2+By_pert_perp**2+Bz_pert_perp**2)\n",
    "    \n",
    "    delta_v_alfven = delta_Bperp_magnitude/np.sqrt(mu_0*(delta_density_data['density_pert']*1e6))\n",
    "    \n",
    "    vx_jss = total_v_data['UX']*1e3\n",
    "    vy_jss = total_v_data['UY']*1e3\n",
    "    vz_jss = total_v_data['UZ']*1e3\n",
    "    \n",
    "    Bx_jss = total_mag_data['BX_JSS']*1e-9\n",
    "    By_jss = total_mag_data['BY_JSS']*1e-9\n",
    "    Bz_jss = total_mag_data['BZ_JSS']*1e-9\n",
    "    \n",
    "    \n",
    "    v_cross_b_x = (vy_jss*Bz_jss - By_jss*vz_jss)\n",
    "    v_cross_b_y = -(vx_jss*Bz_jss - Bx_jss*vz_jss)\n",
    "    v_cross_b_z = (vx_jss*By_jss - Bx_jss*vy_jss)\n",
    "    \n",
    "    Sx_jss = (-(v_cross_b_y*Bz_jss - By_jss*v_cross_b_z))/mu_0\n",
    "    Sy_jss = (v_cross_b_x*Bz_jss - Bx_jss*v_cross_b_z)/mu_0\n",
    "    Sz_jss = -(v_cross_b_x*By_jss - Bx_jss*v_cross_b_y)/mu_0\n",
    "    \n",
    "    \n",
    "    x = total_mag_data['X_JSS']\n",
    "    y = total_mag_data['Y_JSS']\n",
    "    \n",
    "    phi = np.arctan2(y,x)\n",
    "    \n",
    "    S_r = Sx_jss*np.cos(phi) + Sy_jss*np.sin(phi)\n",
    "    S_phi = -np.sin(phi)*Sx_jss + Sy_jss*np.cos(phi)\n",
    "    \n",
    "\n",
    "    \n",
    "    S_dot_zmag = Sx_jss*unitz_x+Sy_jss*unitz_y+Sz_jss*unitz_z\n",
    "    \n",
    "    energy_df = pd.DataFrame({'delta_dot_prod': delta_dot_prod , 'Helicity': Helicity, 'delta_energy': delta_energy_norm, 'norm_Helicity': norm_Helicity, 'norm_residual_energy': residual_energy_Norm, 'v_Alfven': v_Alfven, 'cos_theta':cos_theta, 'delta_vperp_squared_norm': delta_vperp_squared_norm, 'delta_Bperp_squared_norm': delta_Bperp_squared_norm, 'norm_helicity_num': norm_Helicity_num,'S_r':S_r, 'S_phi':S_phi,'S_z':Sz_jss,'S_dot_zmag':S_dot_zmag,'phi':phi})  \n",
    "    print('Combine with z_mag  and R array ...')\n",
    "    \n",
    "    #filename = '/home/mtfranciscovich/Juno-codes/reduced_inbound_1s_pickles/reduced_orbit_' +str(i) +'_1s.pkl'\n",
    "    #picklefile = open(filename,'rb')\n",
    "    #mag_data_mag_frame = pickle.load(picklefile)\n",
    "    z_mag_info = total_mag_data['Z_MAG']\n",
    "    Rj_km = 7.14e4\n",
    "    R_info = np.sqrt(total_mag_data['X_JSS']**2+total_mag_data['Y_JSS']**2)/Rj_km    \n",
    "    energy_df['Z_MAG'] = z_mag_info\n",
    "    energy_df['R'] = R_info\n",
    "    \n",
    "    energy_df = energy_df.dropna()\n",
    "    mean_energy_data = pd.DataFrame({'MEAN_delta_dot_prod': [], 'MEAN_Helicity': [], 'MEAN_delta_energy': [], 'MEAN_norm_Helicity': [], 'MEAN_norm_residual_energy': [], 'MEAN_cos_theta': [], 'residual_energy_test': [], 'norm_helicity_test': [], 'MEAN_S_r':[], 'MEAN_S_phi':[], 'MEAN_S_z':[], 'MEAN_S_dot_zmag':[]})\n",
    "\n",
    "    finish_datetime = (energy_df.index[-1]\n",
    "- timedelta(minutes=np.floor(window_size/2)))\n",
    "    for datetime_index in energy_df.index:\n",
    "        start_datetime = datetime_index\n",
    "        end_datetime = start_datetime + timedelta(minutes=window_size)\n",
    "        mean_datetime_index = pd.DatetimeIndex([\n",
    "        (start_datetime + timedelta(minutes=round(window_size/2))).isoformat()\n",
    "        ])\n",
    "        temp_mean_delta_dot_prod = np.nanmean(energy_df[start_datetime.isoformat(): end_datetime.isoformat()].delta_dot_prod)\n",
    "        temp_mean_Helicity = np.nanmean(energy_df[start_datetime.isoformat(): end_datetime.isoformat()].Helicity)\n",
    "        temp_mean_delta_energy = np.nanmean(energy_df[start_datetime.isoformat(): end_datetime.isoformat()].delta_energy)\n",
    "        temp_mean_norm_Helicity = np.nanmean(energy_df[start_datetime.isoformat(): end_datetime.isoformat()].norm_Helicity)\n",
    "        temp_mean_norm_residual_energy = np.nanmean(energy_df[start_datetime.isoformat(): end_datetime.isoformat()].norm_residual_energy)\n",
    "        temp_mean_cos_theta = np.nanmean(energy_df[start_datetime.isoformat(): end_datetime.isoformat()].cos_theta)\n",
    "        \n",
    "        \n",
    "        temp_mean_vperp_squared_norm = np.nanmean(energy_df[start_datetime.isoformat(): end_datetime.isoformat()].delta_vperp_squared_norm)\n",
    "        temp_mean_Bperp_squared_norm = np.nanmean(energy_df[start_datetime.isoformat(): end_datetime.isoformat()].delta_Bperp_squared_norm)\n",
    "        \n",
    "        temp_res_energy_num = temp_mean_vperp_squared_norm - temp_mean_Bperp_squared_norm\n",
    "        temp_res_energy_denom = temp_mean_vperp_squared_norm + temp_mean_Bperp_squared_norm\n",
    "        temp_mean_residual_energy_test = temp_res_energy_num/temp_res_energy_denom\n",
    "        \n",
    "        temp_mean_norm_hel_num = np.nanmean(energy_df[start_datetime.isoformat(): end_datetime.isoformat()].norm_helicity_num)\n",
    "        temp_mean_norm_helicity_test = temp_mean_norm_hel_num/temp_res_energy_denom\n",
    "        temp_mean_Bperp_squared_norm = np.nanmean(energy_df[start_datetime.isoformat(): end_datetime.isoformat()].delta_Bperp_squared_norm)\n",
    "        temp_mean_S_r = np.nanmean(energy_df[start_datetime.isoformat(): end_datetime.isoformat()].S_r)\n",
    "        temp_mean_S_phi = np.nanmean(energy_df[start_datetime.isoformat(): end_datetime.isoformat()].S_phi)\n",
    "        temp_mean_S_z = np.nanmean(energy_df[start_datetime.isoformat(): end_datetime.isoformat()].S_z)\n",
    "        temp_mean_S_dot_zmag = np.nanmean(energy_df[start_datetime.isoformat(): end_datetime.isoformat()].S_dot_zmag)\n",
    "        \n",
    "        mean_array_to_concat = pd.DataFrame(\n",
    "        {'MEAN_delta_dot_prod': temp_mean_delta_dot_prod,\n",
    "            'MEAN_Helicity': temp_mean_Helicity,\n",
    "            'MEAN_delta_energy' : temp_mean_delta_energy,\n",
    "            'MEAN_norm_Helicity' : temp_mean_norm_Helicity,\n",
    "            'MEAN_norm_residual_energy': temp_mean_norm_residual_energy,\n",
    "            'MEAN_cos_theta': temp_mean_cos_theta,\n",
    "            'residual_energy_test': temp_mean_residual_energy_test,\n",
    "            'norm_helicity_test': temp_mean_norm_helicity_test,\n",
    "            'MEAN_S_r': temp_mean_S_r,\n",
    "            'MEAN_S_phi': temp_mean_S_phi,\n",
    "            'MEAN_S_z': temp_mean_S_z,\n",
    "            'MEAN_S_dot_zmag': temp_mean_S_dot_zmag\n",
    "            \n",
    "            }, index=mean_datetime_index)\n",
    "        mean_energy_data = pd.concat([mean_energy_data, mean_array_to_concat])\n",
    "    \n",
    "        if mean_datetime_index == finish_datetime:\n",
    "            break\n",
    "    energy_df = energy_df[mean_energy_data.index[0].isoformat(): \n",
    "                            mean_energy_data.index[-1].isoformat()]\n",
    "    energy_df = pd.concat([energy_df, mean_energy_data], axis=1)\n",
    "\n",
    "    if save_pickles:\n",
    "        energy_df.to_pickle('/home/mtfranciscovich/Juno-codes/updated_energy_pickles_0423/energy_df_orbit_' + str(i) + '.pkl')\n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

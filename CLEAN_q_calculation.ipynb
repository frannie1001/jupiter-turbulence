{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "488fb3a3",
   "metadata": {},
   "source": [
    "This file makes and pickles q data as well as case study images. Also reads in fits data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a26ad66",
   "metadata": {},
   "source": [
    "Dependencies..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a429448d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "pd.set_option('mode.chained_assignment', None)\n",
    "warnings.simplefilter(\"ignore\", category=RuntimeWarning)\n",
    "import re\n",
    "import pickle\n",
    "import struct\n",
    "from datetime import datetime, timedelta\n",
    "from os import fsdecode\n",
    "import pathlib\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.dates as mdates\n",
    "import matplotlib.gridspec as gs\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import spiceypy as spice\n",
    "import pandas as pd\n",
    "import pycwt as wavelet\n",
    "import scipy.integrate as integrate\n",
    "import scipy.signal as signal\n",
    "from matplotlib.colors import LogNorm\n",
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from spiceypy.spiceypy import xf2eul\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "import math as m\n",
    "\n",
    "import random\n",
    "import os\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dd7bcc7",
   "metadata": {},
   "source": [
    "Classes from juno_classes.py pulled here to alter them to fit my needs..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "633bfb49",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PlotClass:\n",
    "    def __init__(self, axes, xlabel=None, ylabel=None, title=None):\n",
    "        self.axes = axes\n",
    "        self.xlabel = xlabel\n",
    "        self.ylabel = ylabel\n",
    "        self.title = title\n",
    "\n",
    "    def xaxis_datetime_tick_labels(self, x_ticks_labeled,):\n",
    "        \n",
    "        locator = mdates.AutoDateLocator(minticks=5, maxticks=20)\n",
    "        formatter = mdates.ConciseDateFormatter(locator)\n",
    "        self.axes.xaxis.set_major_locator(locator)\n",
    "        self.axes.xaxis.set_major_formatter(formatter)\n",
    "        if not x_ticks_labeled:\n",
    "            self.axes.set_xticklabels([])\n",
    "\n",
    "    def plot(self, x, y, magnitude=False, data_labels=None, xlabel=None, ylabel=None,\n",
    "                         title=None, **kwargs):\n",
    "\n",
    "        if (np.ndim(y) == 1) & (np.ndim(x) == 1):\n",
    "            self.axes.plot(x, y, **kwargs)\n",
    "        elif (np.ndim(y) != 1) & (np.ndim(x) != 1):\n",
    "            self.axes.plot(np.transpose(x), np.transpose(y), **kwargs)\n",
    "        else:\n",
    "            if data_labels is None:\n",
    "                self.axes.plot(x, np.transpose(y), **kwargs)\n",
    "            else:\n",
    "                for i in range(len(y)):\n",
    "                    self.axes.plot(x, y[i], label=data_labels[i], **kwargs)\n",
    "        \n",
    "        if magnitude:\n",
    "            mag = np.array([np.sqrt(np.sum(np.power(i, 2))) for i in np.transpose(y)])\n",
    "            self.axes.plot(x, mag, label='Magnitude', color='black', **kwargs)\n",
    "            self.axes.plot(x, -mag, color='black', **kwargs)\n",
    "\n",
    "        if magnitude and data_labels != None:\n",
    "            self.axes.legend(loc='upper left')\n",
    "        self.axes.set_xlabel(self.xlabel)\n",
    "        self.axes.set_ylabel(self.ylabel)\n",
    "        self.axes.set_title(self.title)\n",
    "\n",
    "    def colormesh(self, x, y, data, color_bar=True, xlabel=None, ylabel=None, title=None, **kwargs):\n",
    "\n",
    "        cwt = self.axes.pcolormesh(x, y, data, shading='auto', **kwargs)\n",
    "        #cwt = self.axes.pcolormesh(x, y, data)\n",
    "        self.axes.set_title(title)\n",
    "        self.axes.set_ylim(y[0], y[-1])\n",
    "        self.axes.set_ylabel(ylabel)\n",
    "        self.axes.set_xlabel(xlabel)\n",
    "        self.axes.set_xlim(x[0], x[-1])\n",
    "        if color_bar:\n",
    "            divider = make_axes_locatable(self.axes)\n",
    "            cax = divider.append_axes(\"right\", '2%', pad='2%')\n",
    "            cbr = plt.colorbar(cwt, cax=cax)\n",
    "            cbr.set_label('Magnitude', rotation=270, labelpad=5, size=8)\n",
    "\n",
    "\n",
    "class CWTData:\n",
    "    def __init__(self, datetime_series, signal, dt, min_freq=None, max_freq=None,\n",
    "                 wave_resolution=6, mother=wavelet.Morlet):\n",
    "        \"\"\"Class for calculating, manipulating, and plotting a continuous wavelet\n",
    "        analysis of a signal.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        datetime_series : array of datetime64[ns] data\n",
    "            Array of datetime variables accompanying the signal data\n",
    "        signal : array\n",
    "            Signal to be analyzed\n",
    "        dt : int\n",
    "            Time in seconds between data samples in the signal\n",
    "        min_freq : float\n",
    "            Lowest frequency in the frequency range to calculate the cwt in.\n",
    "            Leave as None to calculate over whole range.\n",
    "        max_freq : float\n",
    "            Highest frequency in the frequency range to calculate the cwt in.\n",
    "            Leave as None to calculate over whole range.\n",
    "        wave_resolution : int, optional\n",
    "            Resolution to be used in the wavelet packet, by default 6\n",
    "        mother : pycwt mother wavelet class, optional\n",
    "            Wavelet class from the pycwt module, by default pycwt.Morlet\n",
    "\n",
    "        \"\"\"        \n",
    "        self.time_series = datetime_series\n",
    "        self.data = signal\n",
    "        self.wave_resolution = wave_resolution\n",
    "        self.dt = dt\n",
    "        self.min_freq = min_freq\n",
    "        self.max_freq = max_freq\n",
    "        self.mother = mother\n",
    "        self.peaks_found = False\n",
    "        self._get_cwt_matrix()\n",
    "\n",
    "    def _get_cwt_matrix(self):\n",
    "\n",
    "        N = len(self.data)\n",
    "        Fs = 1 / self.dt\n",
    "        f = np.arange(0, N / 2 + 1) * Fs / N\n",
    "        #f = np.linspace(0, N / 2 + 1, num=100) * Fs / N\n",
    "\n",
    "        if self.min_freq is None:\n",
    "            min_index = 1\n",
    "        else:\n",
    "            min_index = min(range(len(f)), key=lambda i: abs(f[i] - self.min_freq)) - 1\n",
    "        if self.max_freq is None:\n",
    "            max_index = len(self.data)\n",
    "        else:\n",
    "            max_index = min(range(len(f)), key=lambda i: abs(f[i] - self.max_freq))\n",
    "        f = f[min_index: max_index]\n",
    "        wave, self.scales, self.freqs, self.coi, fft, fftfreqs = wavelet.cwt(\n",
    "            self.data, self.dt, self.mother(self.wave_resolution), freqs=f\n",
    "        )\n",
    "        #dj = 1 / 12\n",
    "        #s0 = 2 * self.dt\n",
    "        #J = 7 / dj\n",
    "        #wave, scales, self.freqs, self.coi, fft, fftfreqs = wavelet.cwt(self.data, self.dt, dj, s0, J,\n",
    "        #                                              self.mother(self.wave_resolution))\n",
    "        self.power = np.abs(wave)**2\n",
    "        self.coi = self.coi**-1\n",
    "\n",
    "    def remove_coi(self):\n",
    "        # Removes the data affected by the cone of influence\n",
    "        for i, col in enumerate(self.power.T):\n",
    "            col_num = len(col) - i\n",
    "            coi_start_index = min(range(len(self.freqs)),\n",
    "                                  key=lambda i: abs(self.freqs[i] - self.coi[col_num]))\n",
    "            self.power[:coi_start_index, col_num] = np.zeros(coi_start_index)        \n",
    "\n",
    "            \n",
    "    def cwt_plot(self, axes, mark_coi=True, remove_coi=True, title=None, colorbar=True,\n",
    "                 xlabel=None, time_per_major='12H', time_per_minor='1H',\n",
    "                 tick_labels_format='%m-%d %H', x_ticks_labeled=True, **kwargs):\n",
    "\n",
    "        if remove_coi:\n",
    "            self.remove_coi()\n",
    "        \n",
    "        vmin = np.percentile(np.nan_to_num(self.power), 10)\n",
    "        vmax = np.max(np.nan_to_num(self.power))\n",
    "        t = mdates.date2num(self.time_series)    \n",
    "        orbitsData = ['2016-07-31T19:46:02',\n",
    "                  '2016-09-23T03:44:48',\n",
    "                  '2016-11-15T05:36:45',\n",
    "                  '2017-01-07T03:11:30',\n",
    "                  '2017-02-28T22:55:48',\n",
    "                  '2017-04-22T19:14:57',\n",
    "                  '2017-06-14T15:58:35',\n",
    "                  '2017-08-06T11:44:04',\n",
    "                  '2017-09-28T07:51:01',\n",
    "                  '2017-11-20T05:57:23',\n",
    "                  '2018-01-12T03:52:42',\n",
    "                  '2018-03-05T23:55:41',\n",
    "                  '2018-04-27T19:36:40',  \n",
    "                  '2018-06-19T17:30:40',\n",
    "                  '2018-08-11T15:18:43',\n",
    "                  '2018-10-03T10:58:52',   \n",
    "                  '2018-11-25T07:01:26',\n",
    "                  '2019-01-17T05:19:21',   \n",
    "                  '2019-03-11T02:48:11',   \n",
    "                  '2019-05-02T22:18:47',   \n",
    "                  '2019-06-24T18:01:57',   \n",
    "                  '2019-08-16T16:01:52',   \n",
    "                  '2019-10-08T12:52:15',   \n",
    "                  '2019-11-30T07:39:10',\n",
    "                  '2020-01-22T05:44:55',   \n",
    "                  '2020-03-15T03:44:40',   \n",
    "                  '2020-05-07T00:16:41',   \n",
    "                  '2020-06-28T20:24:51',   \n",
    "                  '2020-08-20T16:08:49',   \n",
    "                  '2020-10-12T14:05:43',\n",
    "                  '2020-12-04T11:37:23',   \n",
    "                  '2021-01-26T07:36:06',\n",
    "                  '2021-03-20 08:39:35',\n",
    "                  '2021-05-12 15:29:09']  \n",
    "    \n",
    "        plot_class = PlotClass(axes)\n",
    "        plot_class.colormesh(t, self.freqs, self.power, ylabel='Frequency (Hz)', xlabel=xlabel,\n",
    "                             title=title, color_bar=colorbar, norm=LogNorm(vmin=10**-4, vmax=10**1.2),\n",
    "                             cmap='jet', **kwargs)\n",
    "        if mark_coi:\n",
    "            plot_class.plot(self.time_series, self.coi, linestyle='--', color='black')\n",
    "        axes.set_yscale('log')\n",
    "        plot_class.xaxis_datetime_tick_labels(x_ticks_labeled)\n",
    "        \n",
    "\n",
    "    def peaks_plot(self, axes, plot_title=False, xlabel=True,\n",
    "                   time_per_major='12H', time_per_minor='1H',\n",
    "                   tick_labels_format='%m-%d %H', x_ticks_labeled=True, **kwargs):\n",
    "\n",
    "        if not self.peaks_found:\n",
    "            self._peak_finding()\n",
    "\n",
    "        t = mdates.date2num(self.time_series)\n",
    "        plot_class = PlotClass(axes)\n",
    "        try:\n",
    "            plot_class.colormesh(t, self.freqs, self.power, xlabel=xlabel, title=plot_title,\n",
    "                            norm=LogNorm(),cmap='jet', **kwargs)\n",
    "        except:\n",
    "            plot_class.colormesh(t, self.freqs, self.power, xlabel=xlabel, title=plot_title,\n",
    "                            cmap='jet', **kwargs)\n",
    "        axes.set_yscale('log')\n",
    "        plot_class.xaxis_datetime_tick_labels(x_ticks_labeled)\n",
    "\n",
    "    def peaks_hist(self, axes, min_frequency=1/(20*60*60), max_frequency=1/(60*60),\n",
    "                   freq_per_bin=1, x_units='min'):\n",
    "\n",
    "        if not self.peaks_found:\n",
    "            self._peak_finding(min_frequency, max_frequency)\n",
    "\n",
    "        units_switch = {'sec': 1,\n",
    "                        'min': 60,\n",
    "                        'hour': 3600,\n",
    "                        'day': 86400}\n",
    "        bin_num = round(len(self.peak_freq_range) / freq_per_bin)\n",
    "        axes.hist(self.freq_peaks_hist, bins=bin_num)\n",
    "        axes.tick_params(axis='x', labelsize='small')\n",
    "        axes.set_xticks(np.linspace(min_frequency, max_frequency, 10))\n",
    "        axes.set_xticklabels(np.round(\n",
    "            1/(np.linspace(min_frequency, max_frequency, 10) * units_switch[x_units]), 1\n",
    "            ))\n",
    "        axes.set_xlabel(f'Time ({x_units})')\n",
    "        axes.set_ylabel('Weighted Peaks')\n",
    "        axes.set_yscale('log')\n",
    "\n",
    "    def __psd(self):\n",
    "        freq = self.freqs\n",
    "        cwt_power = self.power\n",
    "        self.psd = np.zeros(len(self.freqs))\n",
    "        for i in range(0, len(freq)):\n",
    "            self.psd[i] = (2/len(freq))*(sum(cwt_power[i, :]))\n",
    "        return self.psd\n",
    "\n",
    "    \n",
    "    def psd_plot(self, axes, x_units, ylabel=None,\n",
    "                 title=None, **kwargs):\n",
    "        \n",
    "        self.__psd()\n",
    "        \n",
    "        plot_class = PlotClass(axes, f'Time({x_units})', ylabel, title)\n",
    "        plot_class.plot(self.freqs, self.psd, xlabel=f'Time ({x_units})', ylabel='Power',\n",
    "                        color='blue', **kwargs)\n",
    "        axes.set_yscale('log')\n",
    "        \n",
    "        units_switch = {'sec': 1, 'min': 60, 'hour': 3600, 'day': 86400}\n",
    "        axes.set_xticks(np.linspace(self.freqs[0], self.freqs[-1], 10))\n",
    "        axes.set_xticklabels(np.round(\n",
    "                    1/(np.linspace(self.freqs[0], self.freqs[-1], 10) \n",
    "                       * units_switch[x_units.lower()]), 1))\n",
    "\n",
    "    def calc_freq_bandpower(self):\n",
    "        \n",
    "        self.remove_coi()\n",
    "        bandpower = np.zeros(len(self.time_series), dtype='float')\n",
    "        for i in range(len(bandpower)):\n",
    "            avg = integrate.trapz(self.power[:, i], self.freqs)\n",
    "            bandpower[i] = avg\n",
    "\n",
    "        return bandpower\n",
    "            \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96fc5197",
   "metadata": {},
   "source": [
    "Q calculation and case study images making within the q calculation. There are also several functions that are used in the calculation..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "291991c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q attempt to make desired psd and time series ...\n",
    "\n",
    "\n",
    "#These are all the dependent functions ...\n",
    "#q calculation is inlcuded to have case study applications\n",
    "\n",
    "def _temp_dist(RRR):    \n",
    "    a1 = -0.116\n",
    "    a2= 2.14\n",
    "    a3= -2.05\n",
    "    a4= 0.491\n",
    "    a5= 0.126\n",
    "    amu=22\n",
    "    rrr=np.log10(RRR/6)\n",
    "    h=a1+a2*rrr+a3*rrr**2.+a4*rrr**3.+a5*rrr**4.\n",
    "\n",
    "    H=10.**h\n",
    "\n",
    "    T=amu*(H/0.64)**2.\n",
    "\n",
    "    T_kelvin = T*11606\n",
    "    return T_kelvin\n",
    "\n",
    "def _v_therm(T_kelvin, mi):\n",
    "    kB = 1.38e-23\n",
    "    vthermal = np.sqrt(2*kB * T_kelvin/mi) # E_perp = 1/2m(v_perp_therm)^2 = kT\n",
    "    return vthermal\n",
    "\n",
    "def _gyro(bx, by, bz, m, z, q):\n",
    "    \"\"\"finds a gyrofreqency given magnetosphere properties.  \\n All inputs must be in\n",
    "    fundamental units (T, m, etc.) \\n Returns scalar qyrofrequency corresponding to given\n",
    "    range of B\"\"\"\n",
    "    mean_b = np.mean(np.sqrt(bx**2 + by**2 + bz**2))\n",
    "    gyrofreq = (z*q/m)*(mean_b)/(2*np.pi)\n",
    "    return gyrofreq\n",
    "\n",
    "def _rho_i(vth, gyrofreq):\n",
    "    rho_i = vth/(2*np.pi*(gyrofreq/z))\n",
    "    return rho_i\n",
    "\n",
    "def kperpgiver(v_rel, freq):\n",
    "    kperp = (2*np.pi*freq)/(v_rel*np.sin(np.pi/2)) \n",
    "    return kperp\n",
    "\n",
    "\n",
    "def _psd(time_array,cwt_power,freq,fs):\n",
    "    \"\"\"Finds PSD as per Tao et. al. 2015 given a morlet wavelet transform, frequency \n",
    "    range, the signal, and sampling frequency. \\n Outputs an array of length of signal\"\"\"\n",
    "    psd = np.zeros(len(freq))\n",
    "    for i in range(0, len(freq)):\n",
    "        if len(np.where(cwt_power[i,:]>0)[0]) > 0:\n",
    "            psd[i] = (2/len(np.where(cwt_power[i,:]>0)[0]))*(sum(cwt_power[i][:]))\n",
    "    return psd\n",
    "\n",
    "def get_break_coeff_and_slopes(theo_break, minf, maxf, cwt_freqs, cwt_psd, gyro, pad, thresh, ftb, acceptable_freqs_min, acceptable_freqs_max):\n",
    "    guess = gyro\n",
    "    minmin = minf\n",
    "    maxmax = maxf\n",
    "    theoretical_break = ftb\n",
    "    keep_index = 0\n",
    "\n",
    "    break_points = np.arange(minf, maxf, .01)\n",
    "    x = (cwt_freqs[np.where(cwt_psd >0)])\n",
    "    y = (cwt_psd[np.where(cwt_psd >0)])\n",
    "    # Define target slope ranges\n",
    "    target_left_min = (-5./3.) - thresh # Example minimum slope for left line\n",
    "    target_left_max = (-5./3.) + thresh# Example maximum slope for left line\n",
    "    target_right_min = (-7./3.) - thresh# Example minimum slope for right line\n",
    "    target_right_max = (-7./3.) + thresh # Example maximum slope for right line\n",
    "\n",
    "    # Prepare to store counts of slopes within the target ranges\n",
    "    break_point_counts = []\n",
    "    \n",
    "    #do it normal\n",
    "    # Iterate over possible break points\n",
    "    \n",
    "    if theo_break:\n",
    "        best_break_point = ftb\n",
    "\n",
    "        if (theoretical_break <= acceptable_freqs_min):\n",
    "        #do what needs to be done if the theo break is less than the acceptable min, make all kaw\n",
    "            left_mask =    0\n",
    "            right_mask = (x > minmin) & (x<maxmax)\n",
    "            \n",
    "            model_left = 0\n",
    "            model_right = LinearRegression().fit(np.log10(x[right_mask]).reshape(-1, 1), np.log10(y[right_mask]))\n",
    "            \n",
    "            slope_left = 0\n",
    "            slope_right = model_right.coef_[0]\n",
    "            \n",
    "            \n",
    "\n",
    "            if (slope_right < (-7./3.) - thresh*2) or (slope_right > (-7./3.) + thresh*2):\n",
    "                keep_index = 1\n",
    "                #if (slope_right > 1.25) or (slope_right < -3.5):\n",
    "                #    slope_left = 0\n",
    "                #    slope_right = 0\n",
    "\n",
    "            \n",
    "\n",
    "        \n",
    "        elif (theoretical_break >= acceptable_freqs_max):\n",
    "            #do what needs to be done if the theo break is greater than the acceptable max, make all mhd\n",
    "            left_mask =    (x > minmin) & (x<maxmax)\n",
    "            right_mask = 0\n",
    "            \n",
    "            model_left = LinearRegression().fit(np.log10(x[left_mask]).reshape(-1, 1), np.log10(y[left_mask]))\n",
    "            model_right = 0\n",
    "            \n",
    "            slope_left = model_left.coef_[0]\n",
    "            slope_right = 0\n",
    "            \n",
    "            \n",
    "  \n",
    "   \n",
    "            if (slope_left < (-5./3.) - thresh) or (slope_left > (-5./3.) + thresh):\n",
    "                keep_index = 1\n",
    "                #if (slope_left > 0.25) or (slope_left < -3.1):\n",
    "                #    slope_left = 0\n",
    "                #    slope_right = 0\n",
    "            \n",
    "        else: \n",
    "        \n",
    "            break_point = theoretical_break\n",
    "            left_mask =    (x < break_point/pad)  & (x > minmin)\n",
    "            right_mask = (x > break_point*pad) & (x<maxmax)\n",
    "            \n",
    "  \n",
    "            \n",
    "\n",
    "            model_left = LinearRegression().fit(np.log10(x[left_mask]).reshape(-1, 1), np.log10(y[left_mask]))\n",
    "\n",
    "            model_right = LinearRegression().fit(np.log10(x[right_mask]).reshape(-1, 1), np.log10(y[right_mask]))\n",
    "            \n",
    "        \n",
    "        \n",
    "            slope_left = model_left.coef_[0]\n",
    "            slope_right = model_right.coef_[0]\n",
    "            \n",
    "\n",
    "            \n",
    "            if (slope_left < (-5./3.) - thresh) or (slope_left > (-5./3.) + thresh):\n",
    "                keep_index = 1\n",
    "         #       if (slope_left > 0.25) or (slope_left < -3.1):\n",
    "          #          slope_left = 0\n",
    "          #          slope_right = 0\n",
    "            elif (slope_right < (-7./3.) - thresh*2) or (slope_right > (-7./3.) + thresh*2):\n",
    "                keep_index = 1\n",
    "           #     if (slope_right > 1.25) or (slope_right < -3.5):\n",
    "           #         slope_left = 0\n",
    "           #         slope_right = 0\n",
    "           # else:\n",
    "            best_break_point = break_point\n",
    "        \n",
    "\n",
    "        \n",
    "    if not theo_break:\n",
    "        for break_point in break_points:\n",
    "        # Split data into two segments\n",
    "            left_mask =    (x < break_point/pad)  & (x > minmin)\n",
    "            right_mask = (x > break_point*pad) & (x<maxmax)\n",
    "\n",
    "            if np.sum(left_mask) > 0 and np.sum(right_mask) > 0:\n",
    "            # Fit lines to both segments\n",
    "                model_left = LinearRegression().fit(np.log10(x[left_mask]).reshape(-1, 1), np.log10(y[left_mask]))\n",
    "                model_right = LinearRegression().fit(np.log10(x[right_mask]).reshape(-1, 1), np.log10(y[right_mask]))\n",
    "            \n",
    "                slope_left = model_left.coef_[0]\n",
    "                slope_right = model_right.coef_[0]\n",
    "\n",
    "            # Count slopes within the target range\n",
    "                if (target_left_min <= slope_left) and (slope_left<= target_left_max):\n",
    "                    count_left = 2\n",
    "                else: \n",
    "                    count_left = 0\n",
    "                if (target_right_min <= slope_right) and (slope_right <= target_right_max):\n",
    "                    count_right = 1\n",
    "                else:\n",
    "                    count_right = 0 \n",
    "            \n",
    "                total_count = count_left + count_right\n",
    "            \n",
    "            # Store the break point and total count\n",
    "                break_point_counts.append((break_point, total_count))\n",
    "\n",
    "        # Convert counts to an array for easier analysis\n",
    "        break_point_counts = np.array(break_point_counts)\n",
    "\n",
    "        # Find the break point with the maximum counts within the target slope ranges\n",
    "        try:\n",
    "            if np.max(break_point_counts[:, 1]) == 0:\n",
    "                best_break_point = -1\n",
    "                slope_right = 0\n",
    "                slope_left = 0\n",
    "            elif np.max(break_point_counts[:, 1]) == 2:\n",
    "        #print(max_count_index[:].mean())\n",
    "        #print(break_point_counts[:,0].mean())\n",
    "        #print(break_point_counts[max_count_index].mean()\n",
    "                break_point_counts = break_point_counts[break_point_counts[:, 1] == 2]\n",
    "                best_break_point = break_point_counts[:,0].mean()\n",
    "                left_mask =    (x < (best_break_point*gyro)/pad)  & (x > minmin)\n",
    "                right_mask = (x > (best_break_point*gyro)*pad) & (x<maxmax)\n",
    "                model_left = LinearRegression().fit(np.log10(x[left_mask]).reshape(-1, 1), np.log10(y[left_mask]))\n",
    "                model_right = LinearRegression().fit(np.log10(x[right_mask]).reshape(-1, 1), np.log10(y[right_mask]))\n",
    "                slope_left = model_left.coef_[0]\n",
    "                slope_right = model_right.coef_[0]\n",
    "\n",
    "\n",
    "            elif np.max(break_point_counts[:, 1]) == 3:\n",
    "                break_point_counts = break_point_counts[break_point_counts[:, 1] == 3]\n",
    "\n",
    "                best_break_point = break_point_counts[:,0].mean()\n",
    "                left_mask =    (x < (best_break_point)/pad)  & (x > minmin)\n",
    "                right_mask = (x > (best_break_point)*pad) & (x<maxmax)\n",
    "                model_left = LinearRegression().fit(np.log10(x[left_mask]).reshape(-1, 1), np.log10(y[left_mask]))\n",
    "                model_right = LinearRegression().fit(np.log10(x[right_mask]).reshape(-1, 1), np.log10(y[right_mask]))\n",
    "                slope_left = model_left.coef_[0]\n",
    "                slope_right = model_right.coef_[0]\n",
    "                \n",
    "                if (slope_left < (-5./3.) - thresh) or (slope_left > (-5./3.) + thresh):\n",
    "                    best_break_point = -1\n",
    "                    slope_left = 0\n",
    "                    slope_right = 0\n",
    "                if (slope_right < (-7./3.) - thresh) or (slope_right > (-7./3.) + thresh):\n",
    "                    best_break_point = -1\n",
    "                    slope_left = 0\n",
    "                    slope_right = 0\n",
    "\n",
    "                # if slope_left > ((-5/3) + thresh) or slope_left < ((-5/3) - thresh):\n",
    "                #     slope_left = 0\n",
    "                #     slope_right = 0\n",
    "                #     best_break_point = -1\n",
    "            else:\n",
    "                best_break_point = -1\n",
    "                slope_left = 10\n",
    "                slope_right = 0\n",
    "        except:\n",
    "            best_break_point = -1\n",
    "            slope_left = 0\n",
    "            slope_right = 0      \n",
    "        \n",
    "        if (theoretical_break <= acceptable_freqs_min) or (best_break_point <= 3e-2) :\n",
    "            #do what needs to be done if the theo break is less than the acceptable min, make all kaw\n",
    "            left_mask =    0\n",
    "            right_mask = (x > minmin) & (x<maxmax)\n",
    "            \n",
    "            model_left = 0\n",
    "            model_right = LinearRegression().fit(np.log10(x[right_mask]).reshape(-1, 1), np.log10(y[right_mask]))\n",
    "            \n",
    "            slope_left = 0\n",
    "            slope_right = model_right.coef_[0]\n",
    "            if best_break_point == -1:\n",
    "                best_break_point = theoretical_break\n",
    "\n",
    "            if (slope_right < (-7./3.) - thresh) or (slope_right > (-7./3.) + thresh):\n",
    "                best_break_point = -1\n",
    "                slope_left = 0\n",
    "                slope_right = 0\n",
    "\n",
    "            \n",
    "\n",
    "        \n",
    "        elif (theoretical_break >= acceptable_freqs_max) or (best_break_point >= 7.5e-2) or (best_break_point == -1):\n",
    "            #do what needs to be done if the theo break is greater than the acceptable max, make all mhd\n",
    "            left_mask =    (x > minmin) & (x<maxmax)\n",
    "            right_mask = 0\n",
    "            \n",
    "            model_left = LinearRegression().fit(np.log10(x[left_mask]).reshape(-1, 1), np.log10(y[left_mask]))\n",
    "            model_right = 0\n",
    "            \n",
    "            slope_left = model_left.coef_[0]\n",
    "            slope_right = 0\n",
    "            \n",
    "            if best_break_point == -1:\n",
    "                best_break_point = theoretical_break\n",
    "            if (slope_left < (-5./3.) - thresh) or (slope_left > (-5./3.) + thresh):\n",
    "                best_break_point = -1\n",
    "                slope_left = 0\n",
    "                slope_right = 0\n",
    "                \n",
    "        elif (theoretical_break <= acceptable_freqs_min) and (best_break_point >= acceptable_freqs_max): \n",
    "                left_mask =    0\n",
    "                right_mask = (x > minmin) & (x<maxmax)\n",
    "                \n",
    "                model_left = 0\n",
    "                model_right = LinearRegression().fit(np.log10(x[right_mask]).reshape(-1, 1), np.log10(y[right_mask]))\n",
    "                \n",
    "                slope_left = 0\n",
    "                slope_right = model_right.coef_[0]\n",
    "                if best_break_point == -1:\n",
    "                    best_break_point = theoretical_break\n",
    "                if (slope_right < (-7./3.) - thresh) or (slope_right > (-7./3.) + thresh):\n",
    "                    best_break_point = -1\n",
    "                    slope_left = 0\n",
    "                    slope_right = 0\n",
    "        \n",
    "        elif (theoretical_break >= acceptable_freqs_max) and (best_break_point <= acceptable_freqs_min): \n",
    "                left_mask =    (x > minmin) & (x<maxmax)\n",
    "                right_mask = 0\n",
    "                \n",
    "                model_left = LinearRegression().fit(np.log10(x[left_mask]).reshape(-1, 1), np.log10(y[left_mask]))\n",
    "                model_right = 0\n",
    "                \n",
    "                slope_left = model_left.coef_[0]\n",
    "                slope_right = 0\n",
    "                if best_break_point == -1:\n",
    "                    best_break_point = theoretical_break\n",
    "                if (slope_left < (-5./3.) - thresh) or (slope_left > (-5./3.) + thresh):\n",
    "                    best_break_point = -1\n",
    "                    slope_left = 0\n",
    "                    slope_right = 0\n",
    "\n",
    "        \n",
    "  \n",
    "\n",
    "    return best_break_point, slope_left, slope_right, x, y, left_mask, right_mask, keep_index\n",
    "\n",
    "\n",
    "def find_nearest_index_value(df, target_datetime):\n",
    "    # Convert target to Timestamp if it's not already\n",
    "    target = pd.to_datetime(target_datetime)\n",
    "\n",
    "    # Find the nearest index\n",
    "    nearest_index = df.index.get_loc(target, method='nearest')\n",
    "\n",
    "    # Retrieve the nearest index and value\n",
    "    nearest_datetime = df.index[nearest_index]\n",
    "    #nearest_value = df[str_param].iloc[nearest_index]\n",
    "    \n",
    "    return nearest_datetime#, nearest_value\n",
    "\n",
    "def mean_changer(df):\n",
    "    mean_x = df['MEAN_BX']\n",
    "    mean_y = df['MEAN_BY']\n",
    "    mean_z = df['MEAN_BZ']\n",
    "    raw_x = df['BX']\n",
    "    raw_y = df['BY']\n",
    "    raw_z = df['BZ']\n",
    "        \n",
    "    mean_vecs = df[['MEAN_BX', 'MEAN_BY', 'MEAN_BZ']]\n",
    "    mean_magnitude = np.sqrt((mean_vecs**2).sum(axis=1))\n",
    "\n",
    "    \n",
    "    perturbed_x = raw_x - mean_x\n",
    "    perturbed_y = raw_y - mean_y\n",
    "    perturbed_z = raw_z - mean_z\n",
    "    \n",
    "    perturbed_df = pd.DataFrame({'B_x_pert': perturbed_x, 'B_y_pert': perturbed_y, 'B_z_pert': perturbed_z})\n",
    "    perturbed_df_perp = pd.DataFrame({'B_x_pert_perp': [], 'B_y_pert_perp': [], 'B_z_pert_perp': []})\n",
    "    perturbed_df_par = pd.DataFrame({'B_x_pert_par': [], 'B_y_pert_par': [], 'B_z_pert_par': []})\n",
    "    par_mag_df = pd.DataFrame({'B_pert_par': []})\n",
    "                                    \n",
    "    for i in range(len(perturbed_x)):\n",
    "        new_df_index = pd.DatetimeIndex([df.index[i].isoformat()])\n",
    "        mean_vecs = df[['MEAN_BX', 'MEAN_BY', 'MEAN_BZ']]\n",
    "        parallel_hat = mean_vecs.iloc[i] / mean_magnitude[i]\n",
    "        perturbed_parallel_mag = np.dot((perturbed_df.iloc[i].to_numpy()), parallel_hat)\n",
    "        perturbed_parallel_vector = np.asarray(perturbed_parallel_mag*parallel_hat)\n",
    "        perturbed_par_x = perturbed_parallel_vector[0]\n",
    "        perturbed_par_y = perturbed_parallel_vector[1]\n",
    "        perturbed_par_z = perturbed_parallel_vector[2]\n",
    "        perturbed_perp_x = perturbed_df.iloc[i]['B_x_pert'] - perturbed_par_x\n",
    "        perturbed_perp_y = perturbed_df.iloc[i]['B_y_pert'] - perturbed_par_y\n",
    "        perturbed_perp_z = perturbed_df.iloc[i]['B_z_pert'] - perturbed_par_z\n",
    "        \n",
    "        \n",
    "        perturbed_df_perp = perturbed_df_perp.append(\n",
    "                pd.DataFrame({'B_x_pert_perp': perturbed_perp_x, 'B_y_pert_perp': perturbed_perp_y, 'B_z_pert_perp': perturbed_perp_z},\n",
    "                             index=new_df_index)\n",
    "            )\n",
    "        perturbed_df_par = perturbed_df_par.append(\n",
    "        pd.DataFrame({'B_x_pert_par': perturbed_par_x, 'B_y_pert_par': perturbed_par_y, 'B_z_pert_par': perturbed_par_z},\n",
    "                        index=new_df_index)\n",
    "        )\n",
    "        par_mag_df = par_mag_df.append(\n",
    "        pd.DataFrame({'B_pert_par': perturbed_parallel_mag},\n",
    "                        index=new_df_index)\n",
    "        )\n",
    "    data_df = pd.concat([df, perturbed_df_perp], axis=1)\n",
    "    data_df  = pd.concat([data_df, perturbed_df_par], axis=1)\n",
    "    data_df = pd.concat([data_df, par_mag_df], axis = 1)\n",
    "    return data_df\n",
    "\n",
    "def _freqrange(minf, maxf, f, fb, psd,pad,left_mask,right_mask):\n",
    "    \"\"\"Finds ranges of freqencies for MHD and KAW scales.\\n  \n",
    "    Inputs: f is frequency range for PSD, and gyro is the gyrofreqency for given domain. \\n\n",
    "    Returns the two frequency arrays and indices (tuples) for the two arrays. \\n b1\n",
    "    corresponds to MHD, b2 to KAW, and b3 to all real points of freqency range.\"\"\"\n",
    "\n",
    "    b1 = left_mask\n",
    "    freq_mhd = f[b1]\n",
    "    \n",
    "\n",
    "    b2 = right_mask\n",
    "    freq_kaw = f[b2]\n",
    "    \n",
    "    try:\n",
    "        if b1 ==0:\n",
    "            freq_mhd = None\n",
    "        pass\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        if b2 ==0:\n",
    "            freq_kaw = None\n",
    "        pass\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    b3 = np.where((f>0) & (f<0.5)) \n",
    "\n",
    "    b4  = np.where((f>minf) & (f<maxf) & (psd>0))  \n",
    "    all_needed_freqs = f[b4]             \n",
    "\n",
    "    return freq_mhd, freq_kaw, all_needed_freqs, b1, b2, b3, b4\n",
    "\n",
    "def _q_calc(one_equation, psd_perp, freq, b1, b2, b4,  v_rel, density,rho_i, theta_rad):\n",
    "    \"\"\"Takes PSD of perpendicular component and other parameters to find q MHD \n",
    "    and q KAW.  \\n Every parameter must be in base units (T, kg, m, etc).  \\n Empirical\n",
    "    parameters are subject to adjustment below.  \\n Outputs ranges of q MHD and q KAW \n",
    "    over freqency domains, according to b1 and b2 (respectively MHD and KAW freqency \n",
    "    domains. \\n MAG vector components used only to find theta for k perp.  \"\"\"\n",
    "    \n",
    "    \n",
    "    \n",
    "    delta_b_perp3 = (psd_perp*freq)**(3/2)                                                \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    mu_0 = np.pi*4*1e-7\n",
    "    kperp = (2*np.pi*freq)/(v_rel*np.sin(theta_rad))  \n",
    "    \n",
    "    sintheta_mean = (np.sin(theta_rad)).mean()\n",
    "\n",
    "\n",
    "    kperp_mean_mhd = kperp[b1].mean()\n",
    "    \n",
    "    v_mean = v_rel.mean()\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "    qkaw = (0.5*(delta_b_perp3[b2])*kperp[b2]/np.sqrt(mu_0**3*density))*(1+kperp[b2]**2*rho_i**2)**0.5*(1+(1/(1+kperp[b2]**2*rho_i**2))*(1/(1+1.25*kperp[b2]**2*rho_i**2))**2)\n",
    "    qmhd = (delta_b_perp3[b1])*kperp[b1]/(np.sqrt((mu_0**3)*density))\n",
    "    q_mhd_freqs = freq[b1]\n",
    "    q_all_freqs = freq[b4]\n",
    "    q_kaw_freqs = freq[b2]\n",
    "    kperps = kperp[b1]\n",
    "    rho_i = rho_i\n",
    "    \n",
    "    if one_equation:\n",
    "        qmhd = (0.5*(delta_b_perp3[b1])*kperp[b1]/np.sqrt(mu_0**3*density))*(1+kperp[b1]**2*rho_i**2)**0.5*(1+(1/(1+kperp[b1]**2*rho_i**2))*(1/(1+1.25*kperp[b1]**2*rho_i**2))**2)\n",
    "        q_all = (0.5*(delta_b_perp3[b4])*kperp[b4]/np.sqrt(mu_0**3*density))*(1+kperp[b4]**2*rho_i**2)**0.5*(1+(1/(1+kperp[b4]**2*rho_i**2))*(1/(1+1.25*kperp[b4]**2*rho_i**2))**2)\n",
    "    mean_delta_bperp3_psd_mhd = delta_b_perp3[b1].mean()\n",
    "    \n",
    "    freqs_mean_mhd = q_mhd_freqs.mean()\n",
    "    try:\n",
    "        if b1 == 0:\n",
    "            qmhd = 100\n",
    "        pass\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        if b2 ==0:\n",
    "            qkaw = 100\n",
    "        pass\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    return q_all, qmhd, qkaw, q_mhd_freqs, q_kaw_freqs, q_all_freqs, kperps, rho_i, mean_delta_bperp3_psd_mhd, kperp_mean_mhd, sintheta_mean, v_mean, freqs_mean_mhd\n",
    "\n",
    "\n",
    "m = 23/6.0229e26\n",
    "z = 1.6\n",
    "q = 1.6e-19\n",
    "\n",
    "\n",
    "\n",
    "#Here is where the actuall q function is ... This version will be hardcoded without the empirical formula to make sure it takes exact densities\n",
    "\n",
    "def _get_q(case_study, case_directory, compression_df,one_equation, theo_break, z_mag_df,delta_v_df,minf_index, maxf_index, minf, maxf, data_df, part_df, interval, dt, filter_magnitude, fits, moments,orbit_number, case_chance, test,empirical =False, remove_coi = False,acceptable_freqs_min = 2e-2, acceptable_freqs_max = 8e-2):\n",
    "    if not remove_coi:\n",
    "        print('not gonna remove cone')\n",
    "    else:\n",
    "        print('gonna remove cone')\n",
    "    #Wherever it says \"data_df\" was originally \"self.data_df\". This was changed because the mean field takes a long time to run, it is now a seperate input when the class is called\n",
    "    \n",
    "    amu = 1.67*10**-27\n",
    "    \n",
    "    m16 = 24*amu\n",
    "    mo2 = 16*amu\n",
    "    ms = 32*amu\n",
    "    ms3 = 32*amu\n",
    "    \n",
    "    \n",
    "    mean_q_mhd = np.array([])\n",
    "    mean_q_kaw = np.array([])\n",
    "    \n",
    "    mean_q = np.array([])\n",
    "    mean_z = np.array([])\n",
    "    mean_R = np.array([])\n",
    "    mean_b_perp = np.array([])\n",
    "    mean_density_array = np.array([])\n",
    "    q_mean_whole_range = np.array([])\n",
    "    mean_vphi_array = np.array([])\n",
    "    \n",
    "    \n",
    "    mean_sintheta_array = np.array([])\n",
    "    \n",
    "    mean_freqs_array = np.array([])\n",
    "    \n",
    "    mean_v_array = np.array([])\n",
    "    \n",
    "    t=1\n",
    "\n",
    "    mean_kperps = np.array([])\n",
    "    mean_delta_bperp3_array = np.array([])\n",
    "\n",
    "    q_kaw_slopes = []\n",
    "    q_mhd_slopes = []\n",
    "    breaks = []\n",
    "    gyros = []\n",
    "    rho_i_array = []\n",
    "    theta_array = []\n",
    "    avg_times = []\n",
    "    local_time_array = []\n",
    "    num_intervals = np.ceil((data_df.index.max().to_pydatetime()\n",
    "                        - data_df.index.min().to_pydatetime())/(timedelta(minutes=interval)))\n",
    "    for i in range(0,int(num_intervals)):\n",
    "        start_index = (data_df.index[0]\n",
    "                        + timedelta(minutes=i*interval))\n",
    "        end_index = (data_df.index[0]\n",
    "                        + timedelta(minutes=(i+1)*interval))\n",
    "        interval_time_series = data_df[start_index: end_index].index\n",
    "        \n",
    "        avg_index = pd.to_datetime(start_index) + pd.Timedelta(minutes=interval/2)\n",
    "\n",
    "        if ((pd.to_datetime(end_index) - pd.to_datetime(start_index)) <  (pd.Timedelta(minutes = interval+5)) ) and ((pd.to_datetime(end_index) - pd.to_datetime(start_index)) > (pd.Timedelta(minutes = interval-5))):\n",
    "            interval_R = data_df['R'][start_index: end_index].to_numpy()\n",
    "            \n",
    "            \n",
    "            interval_Z = z_mag_df[start_index: end_index].to_numpy()\n",
    "            mean_R_value = interval_R.mean()\n",
    "            mean_Z_value = interval_Z.mean()\n",
    "            #interval_perptotal = data_df['B_PERP_TOT'][start_index: end_index].to_numpy()\n",
    "            interval_perp_x = data_df['B_x_pert_perp'][start_index: end_index].to_numpy()\n",
    "            interval_perp_y = data_df['B_y_pert_perp'][start_index: end_index].to_numpy()\n",
    "            interval_perp_z = data_df['B_z_pert_perp'][start_index: end_index].to_numpy()\n",
    "            interval_perptotal = np.sqrt((interval_perp_x.mean())**2+(interval_perp_y.mean())**2+(interval_perp_z.mean())**2)\n",
    "            interval_par_x = data_df['B_x_pert_par'][start_index: end_index].to_numpy()\n",
    "            interval_par_y = data_df['B_y_pert_par'][start_index: end_index].to_numpy()\n",
    "            interval_par_z = data_df['B_z_pert_par'][start_index: end_index].to_numpy()\n",
    "            interval_MEAN_BX = data_df['MEAN_BX'][start_index: end_index].to_numpy()*1e-9\n",
    "            interval_MEAN_BY = data_df['MEAN_BY'][start_index: end_index].to_numpy()*1e-9\n",
    "            interval_MEAN_BZ = data_df['MEAN_BZ'][start_index: end_index].to_numpy()*1e-9\n",
    "            interval_compression_df = compression_df[start_index: end_index]\n",
    "            interval_compression_df_index = interval_compression_df.index\n",
    "\n",
    "            interval_Br = data_df['BR'][start_index: end_index].to_numpy()\n",
    "            interval_Btheta = data_df['BTHETA'][start_index: end_index].to_numpy()\n",
    "            interval_Bphi = data_df['BPHI'][start_index: end_index].to_numpy()\n",
    "            try:\n",
    "                interval_v_perp_x = delta_v_df['u_x_pert_perp'][start_index: end_index].to_numpy()*1e3\n",
    "                interval_v_perp_y = delta_v_df['u_y_pert_perp'][start_index: end_index].to_numpy()*1e3\n",
    "                interval_v_perp_z = delta_v_df['u_z_pert_perp'][start_index: end_index].to_numpy()*1e3\n",
    "            except:\n",
    "                continue\n",
    "            interval_v_perp_index = delta_v_df['u_x_pert_perp'][start_index: end_index].index\n",
    "            interval_B_perp_index = data_df['B_x_pert_perp'][start_index: end_index].index\n",
    "\n",
    "            mean_Br = interval_Br.mean()\n",
    "            mean_Btheta =interval_Btheta.mean()\n",
    "            mean_Bphi = interval_Bphi.mean()\n",
    "\n",
    "            mean_delta_b_perp_value = interval_perptotal.mean()\n",
    "            \n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "            try:\n",
    "                len(interval_perp_x)\n",
    "                if len(interval_perp_x) < 1:\n",
    "                    #print('too short')\n",
    "                    continue\n",
    "            except:\n",
    "                print('too short')\n",
    "                continue\n",
    "            interval_mean_B_mag = np.sqrt(data_df['MEAN_BX'][start_index: end_index]**2+data_df['MEAN_BY'][start_index: end_index]**2 +data_df['MEAN_BZ'][start_index: end_index]**2).to_numpy()\n",
    "            if not filter_magnitude:\n",
    "                pass\n",
    "            else:\n",
    "                print('filtering')\n",
    "                if interval_perptotal >= filter_magnitude*interval_mean_B_mag.mean():\n",
    "                    continue\n",
    "                else:\n",
    "                    pass\n",
    "            \n",
    "            if empirical:\n",
    "                pass\n",
    "                '''\n",
    "                try:\n",
    "                    interval_gyro = _gyro(data_df['BX'][start_index: end_index]*10**-9, data_df['BY'][start_index: end_index]*10**-9, data_df['BZ'][start_index: end_index]*10**-9,m , z, q)\n",
    "                    interval_R = data_df['R'][start_index: end_index].to_numpy()\n",
    "                    interval_Z = data_df['Z_MAG'][start_index: end_index].to_numpy()\n",
    "                    vco = (12.6)*interval_R*(1e3)\n",
    "                    #interval_vphi = vco/((1+(interval_R/50)**2))\n",
    "                    interval_vphi = vco/((1+(interval_R/50)**2))\n",
    "                    #interval_vphi = vco*((1.12-(interval_R/50)))\n",
    "                    a1 = 1987\n",
    "                    b1 = -8.2\n",
    "                    a2 = 14\n",
    "                    b2 = -3.2\n",
    "                    a3 = 0.05\n",
    "                    b3 = -0.65\n",
    "                    interval_n =a1*(interval_R/6)**b1 + a2*(interval_R/6)**b2 +a3*(interval_R/6)**b3\n",
    "                    mean_n = interval_n.mean()*(100**3)\n",
    "                    mean_density = (23/6.0229e26)*mean_n\n",
    "                    mean_temp = _temp_dist(interval_R).mean()\n",
    "                    mean_vth = _v_therm(mean_temp, m).mean()\n",
    "                    mean_vphi = interval_vphi.mean()\n",
    "\n",
    "                   # if interval_R.mean()>20:\n",
    "                    #    mean_vphi = 200e3\n",
    "                   # else:\n",
    "                    #    mean_vphi = interval_vphi.mean()\n",
    "\n",
    "                    interval_rho_i = _rho_i(mean_vth, interval_gyro)\n",
    "                    mean_rho_i = interval_rho_i\n",
    "                except:\n",
    "                    continue\n",
    "                '''\n",
    "            elif fits:\n",
    "                interval_vphi = part_df['   \"ur\"'][start_index: end_index].dropna()\n",
    "                if len(interval_vphi)<1:\n",
    "                    continue\n",
    "                else:\n",
    "                    try:\n",
    "                        interval_vphi = part_df[' \"uphi\"'][start_index: end_index].to_numpy()\n",
    "                        interval_vr = part_df['   \"ur\"'][start_index: end_index].to_numpy()\n",
    "                        interval_vtheta = part_df['   \"uz\"'][start_index: end_index].to_numpy()\n",
    "                        interval_n = part_df['      \"n\"'][start_index: end_index].to_numpy()\n",
    "                        interval_m16 = part_df['r[MQ16]'][start_index: end_index].to_numpy()\n",
    "                        interval_mo = part_df['r[O2+]'][start_index: end_index].to_numpy()\n",
    "                        interval_ms = part_df['r[S+]'][start_index: end_index].to_numpy()\n",
    "                        interval_ms3 = part_df['r[S3+]'][start_index: end_index].to_numpy()\n",
    "                        interval_temp = part_df['    \"T\"'][start_index: end_index].to_numpy()\n",
    "                        interval_local_time = part_df[' \"LT\"'][start_index: end_index].to_numpy()\n",
    "                        datetime_list = pd.date_range(start=start_index, end=end_index, freq='1s')\n",
    "                        datetime_series = pd.Series(datetime_list)\n",
    "                        mean_datetime = pd.to_datetime(datetime_series.mean())\n",
    "                        mean_vphi = np.nanmean(interval_vphi)*1e3\n",
    "                        mean_vr = np.nanmean(interval_vr)*1e3\n",
    "                        mean_vtheta = np.nanmean(interval_vtheta)*1e3\n",
    "                        mean_n = np.nanmean(interval_n)\n",
    "                        mean_m16 = np.nanmean(interval_m16)\n",
    "                        mean_mo = np.nanmean(interval_mo)\n",
    "                        mean_ms = np.nanmean(interval_ms)\n",
    "                        mean_ms3 = np.nanmean(interval_ms3)\n",
    "                        mean_temp = np.nanmean(interval_temp)\n",
    "                        mean_m = mean_m16*m16 + mean_mo*mo2 +mean_ms*ms+mean_ms3*ms3\n",
    "                        interval_gyro = _gyro(data_df['BX'][start_index: end_index]*10**-9, data_df['BY'][start_index: end_index]*10**-9, data_df['BZ'][start_index: end_index]*10**-9,mean_m , z, q)\n",
    "                        mean_density = mean_m * mean_n*1e6\n",
    "                        mean_vth = _v_therm(mean_temp, mean_m)\n",
    "                        mean_rho_i = _rho_i(mean_vth, interval_gyro)\n",
    "                        mean_local_time = np.nanmean(interval_local_time)\n",
    "                    except:\n",
    "                        continue\n",
    "            elif moments:\n",
    "                try:\n",
    "                    interval_vphi = part_df['vphi'][start_index: end_index].to_numpy()\n",
    "                    interval_vr = part_df['vr'][start_index: end_index].to_numpy()\n",
    "                    interval_vtheta = part_df['vtheta'][start_index: end_index].to_numpy()\n",
    "                    interval_n = part_df['n'][start_index: end_index].to_numpy()\n",
    "                    interval_m = 3.2*10**-26\n",
    "                    interval_temp = part_df['Temp'][start_index: end_index].to_numpy()\n",
    "                    interval_local_time = part_df['SC_POS_LOCAL_TIME'][start_index: end_index].to_numpy()\n",
    "                    datetime_list = pd.date_range(start=start_index, end=end_index, freq='1s')\n",
    "                    datetime_series = pd.Series(datetime_list)\n",
    "                    mean_datetime = pd.to_datetime(datetime_series.mean())\n",
    "                    if len(interval_vphi)<1:\n",
    "                        mean_vphi = (part_df['vphi'][find_nearest_index_value(part_df, mean_datetime)])*1e3\n",
    "                        mean_vr = (part_df['vr'][find_nearest_index_value(part_df, mean_datetime)])*1e3\n",
    "                        mean_vtheta = (part_df['vtheta\"'][find_nearest_index_value(part_df, mean_datetime)])*1e3\n",
    "                        #  mean_R = part_df['  \"R\"'][find_nearest_index_value(part_df, mean_datetime)]\n",
    "                        mean_n = part_df['n'][find_nearest_index_value(part_df, mean_datetime)]\n",
    "                        mean_m = interval_m\n",
    "                        interval_gyro = _gyro(data_df['BX'][start_index: end_index]*10**-9, data_df['BY'][start_index: end_index]*10**-9, data_df['BZ'][start_index: end_index]*10**-9,mean_m , z, q)\n",
    "                        mean_density = mean_n* mean_m*1e6\n",
    "                        #  mean_temp = part_df['    \"T\"'][find_nearest_index_value(part_df, mean_datetime)]\n",
    "                        mean_temp = _temp_dist(mean_R_value)\n",
    "                        mean_vth = _v_therm(mean_temp, mean_m)\n",
    "                        mean_rho_i = _rho_i(mean_vth, interval_gyro)\n",
    "                        mean_local_time = part_df['SC_POS_LOCAL_TIME'][find_nearest_index_value(part_df, mean_datetime)]\n",
    "                    else:\n",
    "                        mean_vphi = interval_vphi.mean()*1e3\n",
    "                        mean_vr = interval_vr.mean()*1e3\n",
    "                        mean_vtheta = interval_vtheta.mean()*1e3\n",
    "                        mean_n = interval_n.mean()\n",
    "                        mean_m = interval_m\n",
    "                        mean_temp = interval_temp.mean()\n",
    "                        interval_gyro = _gyro(data_df['BX'][start_index: end_index]*10**-9, data_df['BY'][start_index: end_index]*10**-9, data_df['BZ'][start_index: end_index]*10**-9,mean_m , z, q)\n",
    "                        mean_density = mean_m * mean_n*1e6\n",
    "                        #mean_temp = part_df['    \"T\"'][find_nearest_index_value(part_df, mean_datetime)]\n",
    "                        mean_temp = _temp_dist(mean_R_value)\n",
    "                        mean_vth = _v_therm(mean_temp, mean_m)\n",
    "                        mean_rho_i = _rho_i(mean_vth, interval_gyro)\n",
    "                        mean_local_time = interval_local_time.mean()\n",
    "                except:\n",
    "                    continue\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            fs = int(1/dt)\n",
    "            dot_prod = mean_vr*mean_Br+mean_vtheta*mean_Btheta+mean_vphi*mean_Bphi\n",
    "            v_mag = np.sqrt(mean_vr**2+mean_vtheta**2+mean_vphi**2)\n",
    "            B_mag = np.sqrt(mean_Br**2+mean_Bphi**2+mean_Btheta**2)\n",
    "            mag_values_mult = v_mag*B_mag\n",
    "            theta_rad = math.acos(dot_prod/mag_values_mult)\n",
    "            theta_deg = math.degrees(theta_rad)\n",
    "            mu_0 = np.pi*4e-7\n",
    "            \n",
    "            v_Alfven = ((interval_mean_B_mag*1e-9))/np.sqrt(mu_0*mean_density)\n",
    "            \n",
    "            \n",
    "            \n",
    "        \n",
    "            \n",
    "\n",
    "            try:\n",
    "\n",
    "                cwt_perp_x = CWTData(interval_time_series,\n",
    "                                    interval_perp_x,\n",
    "                                    dt)\n",
    "            \n",
    "                cwt_perp_y = CWTData(interval_time_series,\n",
    "                                    interval_perp_y,\n",
    "                                    dt)\n",
    "                \n",
    "                cwt_perp_z = CWTData(interval_time_series,\n",
    "                                    interval_perp_z,\n",
    "                                    dt)\n",
    "                if remove_coi:\n",
    "                    cwt_perp_x.remove_coi()\n",
    "                    cwt_perp_y.remove_coi()\n",
    "                    cwt_perp_z.remove_coi()\n",
    "                psd_x = _psd(interval_perp_x, cwt_perp_x.power, cwt_perp_x.freqs, fs)*10**-18\n",
    "                psd_y = _psd(interval_perp_y, cwt_perp_y.power, cwt_perp_y.freqs, fs)*10**-18\n",
    "                psd_z = _psd(interval_perp_z, cwt_perp_z.power, cwt_perp_z.freqs, fs)*10**-18\n",
    "                psd_perp = psd_x + psd_y + psd_z\n",
    "                #psd_perp = np.sqrt(psd_x**2+psd_y**2+psd_z**2)\n",
    "\n",
    "                \n",
    "                psd_perp = psd_perp[np.where(psd_perp>0)]\n",
    "                freqs = cwt_perp_x.freqs[np.where(psd_perp>0)]\n",
    "                                            \n",
    "                K_b = 1.38e-23\n",
    "                charge = 1.6e-19\n",
    "                \n",
    "\n",
    "\n",
    "                rho_i = np.sqrt(2*mean_temp*11606*K_b*mean_m)/(1.6*charge*np.abs(interval_mean_B_mag.mean())*10**-9)\n",
    "                theta_rad = math.acos(dot_prod/mag_values_mult)\n",
    "                mean_sintheta = np.sin(np.mean(theta_rad))\n",
    "                theoretical_break_raw= v_mag*mean_sintheta/(2*np.pi*rho_i)\n",
    "                \n",
    "\n",
    "                \n",
    "                thresh = .33\n",
    "                \n",
    "\n",
    "                acceptable_freqs_min = 2e-2    \n",
    "                break_coeff, mhd_slope, kaw_slope, x, y, left_mask, right_mask, keep_index = get_break_coeff_and_slopes(theo_break,minf_index, maxf_index, freqs, psd_perp, interval_gyro, 1, thresh, theoretical_break_raw, acceptable_freqs_min, acceptable_freqs_max)\n",
    "            \n",
    "            except:\n",
    "                break_coeff = -1\n",
    "                continue\n",
    "\n",
    "            if (break_coeff == -1) or (keep_index == 1):\n",
    "                rho_i = np.sqrt(2*mean_temp*11606*K_b*mean_m)/(1.6*charge*np.abs(interval_mean_B_mag.mean())*10**-9)\n",
    "                theoretical_break_raw= v_mag*mean_sintheta/(2*np.pi*rho_i)\n",
    "                mean_q_mhd = np.append(mean_q_mhd, -1)\n",
    "                mean_q_kaw = np.append(mean_q_kaw, -1)\n",
    "                mean_q = np.append(mean_q, -1)\n",
    "                mean_z = np.append(mean_z, interval_Z.mean())\n",
    "                mean_R = np.append(mean_R, interval_R.mean())\n",
    "                \n",
    "                mean_sintheta_array = np.append(mean_sintheta_array, -1)\n",
    "                \n",
    "                mean_freqs_array = np.append(mean_freqs_array, -1)\n",
    "                \n",
    "                mean_v_array = np.append(mean_v_array, -1)\n",
    "                \n",
    "                mean_kperps = np.append(mean_kperps, -1)\n",
    "                mean_delta_bperp3_array = np.append(mean_delta_bperp3_array, -1)\n",
    "\n",
    "\n",
    "                local_time_array = np.append(local_time_array, mean_local_time)\n",
    "                mean_b_perp = np.append(mean_b_perp, mean_delta_b_perp_value)\n",
    "                mean_density_array = np.append(mean_density_array, mean_density)\n",
    "                mean_vphi_array = np.append(mean_vphi_array, mean_vphi)\n",
    "                q_kaw_slopes.append(kaw_slope)\n",
    "                q_mhd_slopes.append(mhd_slope)\n",
    "                avg_times.append(avg_index)\n",
    "                q_mean_whole_range = np.append(q_mean_whole_range,-1)\n",
    "                continue\n",
    "            else:\n",
    "                fb = break_coeff\n",
    "                freq_mhd, freq_kaw, all_freqs, b1, b2, b3,b4 = _freqrange(minf, maxf,freqs, fb, psd_perp,1,left_mask,right_mask)\n",
    "                q_all , q_mhd, q_kaw, q_mhd_freqs, q_kaw_freqs,q_all_freqs, kperps, rho_i, delta_bperp3_value_mhd, kperp_value_mhd, mean_sintheta, mean_v, mean_freq = _q_calc(one_equation,psd_perp, freqs,\n",
    "                                    b1, b2,b4, v_mag, mean_density, rho_i, theta_rad)    #this second b1 was actually b2, just b2 for now to do calc with both equation in same freq range\n",
    "                mean_sintheta_array = np.append(mean_sintheta_array, mean_sintheta)\n",
    "                \n",
    "                q_kaw_slopes.append(kaw_slope)\n",
    "                q_mhd_slopes.append(mhd_slope)\n",
    "                breaks.append(fb)\n",
    "                gyros.append(interval_gyro)\n",
    "                rho_i_array.append(mean_rho_i)\n",
    "                q_mean_whole_range = np.append(q_mean_whole_range, np.mean(q_all))\n",
    "                \n",
    "                \n",
    "\n",
    "                if type(q_mhd) is int:\n",
    "                    mean_q = np.append(mean_q, np.mean(q_kaw))\n",
    "                elif type(q_kaw) is int:\n",
    "                    mean_q = np.append(mean_q, np.mean(q_mhd))\n",
    "                else:\n",
    "                    mean_q = np.append(mean_q, (np.mean(q_mhd) + np.mean(q_kaw))/2)\n",
    "                    \n",
    "                \n",
    "                \n",
    "                \n",
    "                if type(left_mask) is int:\n",
    "                    mean_q_mhd = np.append(mean_q_mhd, 100)\n",
    "                else: \n",
    "                    mean_q_mhd = np.append(mean_q_mhd, np.mean(q_mhd))\n",
    "\n",
    "                if type(right_mask) is int:\n",
    "                    mean_q_kaw = np.append(mean_q_kaw, 100)\n",
    "                else:\n",
    "                    mean_q_kaw = np.append(mean_q_kaw, np.mean(q_kaw))\n",
    "                \n",
    "                \n",
    "                \n",
    "\n",
    "                mean_delta_bperp3_array = np.append(mean_delta_bperp3_array, delta_bperp3_value_mhd)\n",
    "                mean_kperps = np.append(mean_kperps, kperp_value_mhd)\n",
    "                \n",
    "                mean_freqs_array = np.append(mean_freqs_array, mean_freq)\n",
    "                \n",
    "                mean_v_array = np.append(mean_v_array, mean_v)\n",
    "\n",
    "\n",
    "\n",
    "                mean_R = np.append(mean_R, mean_R_value)\n",
    "                mean_z = np.append(mean_z, mean_Z_value)\n",
    "                mean_density_array = np.append(mean_density_array, mean_density)\n",
    "                mean_vphi_array = np.append(mean_vphi_array, mean_vphi)\n",
    "                theta_array = np.append(theta_array, theta_deg)\n",
    "                mean_b_perp = np.append(mean_b_perp, mean_delta_b_perp_value)\n",
    "                avg_times.append(avg_index)\n",
    "                local_time_array = np.append(local_time_array, mean_local_time)\n",
    "                \n",
    "                \n",
    "                #case study stuff\n",
    "                \n",
    "                if case_study:\n",
    "\n",
    "                    if (mean_R_value < 35) & (mean_R_value > 15) & (np.abs(mean_Z_value) < 2) & (break_coeff !=-1) & (mean_sintheta > 0.1):\n",
    "                        #print('made it to case study')\n",
    "                        \n",
    "                        chance = random.randint(1,100)\n",
    "                        if chance <= case_chance:\n",
    "                            \n",
    "\n",
    "                            directory = case_directory+'/Orbit_'+str(orbit_number) +'_Case_' +str(t)+'/'\n",
    "                            #if test:\n",
    "                            #    directory = '/home/mtfranciscovich/Juno-codes/test2_case_study_images_fits/Orbit_'+str(orbit_number) +'_Case_' +str(t)+'_test/'\n",
    "\n",
    "                            if not os.path.exists(directory):\n",
    "                                os.makedirs(directory)\n",
    "                                \n",
    "                                \n",
    "                            fig, ax = plt.subplots(6, figsize = (25,12), sharex = 'all')\n",
    "\n",
    "\n",
    "                            b_perp_tot = np.sqrt(interval_perp_x**2 + interval_perp_y**2 + interval_perp_z**2)\n",
    "                            b_par_tot = np.sqrt(interval_par_x**2 + interval_par_y**2 + interval_par_z**2)\n",
    "                            #ax[1].plot(vitaly_data_mean['B_PERP_TOT'], ls = \"-.\",c='red')\n",
    "                            \n",
    "                            \n",
    "                            ax[0].plot(data_df['R'][start_index: end_index].index, interval_Br)\n",
    "                            ax[1].plot(data_df['R'][start_index: end_index].index, interval_Btheta)\n",
    "                            ax[2].plot(data_df['R'][start_index: end_index].index, interval_Bphi)\n",
    "                            ax[3].plot(data_df['R'][start_index: end_index].index, b_par_tot)\n",
    "                            ax[4].plot(data_df['R'][start_index: end_index].index, b_perp_tot)\n",
    "                            ax[5].plot(data_df['R'][start_index: end_index].index, interval_Z)\n",
    "                            \n",
    "                            \n",
    "                            ax[0].set_ylabel(r'$B_r$ [nT]')\n",
    "                            ax[1].set_ylabel(r'$B_{\\theta}$ [nT]')\n",
    "                            ax[2].set_ylabel(r'$B_{\\phi}$ [nT]')\n",
    "                            ax[3].set_ylabel(r'${\\delta}B_{||}$ [nT]')\n",
    "                            ax[4].set_ylabel(r'${\\delta}B_{\\perp}$ [nT]')\n",
    "                            ax[5].set_ylabel(r'$Z_{mag} [R_J]$')\n",
    "                            \n",
    "                            \n",
    "                            ax[0].set_title('Magnetometer Data, L = ' +str(round(mean_R_value,3)) +', $Z_{mag} = $' +str(round(mean_Z_value,3)))\n",
    "\n",
    "                            \n",
    "                            plt.savefig(directory+'/magnetometer', facecolor='white')\n",
    "\n",
    "                            \n",
    "                            plt.close()\n",
    "                            \n",
    "                            fig,ax = plt.subplots(3,figsize =(16,16))\n",
    "                            cwt_perp_x.cwt_plot(ax[0], remove_coi=False)\n",
    "                            cwt_perp_y.cwt_plot(ax[1],remove_coi=False)\n",
    "                            cwt_perp_z.cwt_plot(ax[2],remove_coi=False)\n",
    "\n",
    "\n",
    "                            ax[0].set_title('Power X Perp, L = ' +str(round(mean_R_value,3)) +', $Z_{mag} = $' +str(round(mean_Z_value,3)))\n",
    "                            ax[1].set_title('Power Y Perp, L = ' +str(round(mean_R_value,3)) +', $Z_{mag} = $' +str(round(mean_Z_value,3)))\n",
    "                            ax[2].set_title('Power Z Perp, L = ' +str(round(mean_R_value,3)) +', $Z_{mag} = $' +str(round(mean_Z_value,3)))\n",
    "                            \n",
    "                            \n",
    "                            plt.savefig(directory+'/CWT', facecolor='white')\n",
    "                            \n",
    "                            plt.close()\n",
    "                            plt.figure(figsize=(10, 6))\n",
    "                            plt.loglog(x, y, color = 'black')\n",
    "                            \n",
    "                            if mhd_slope != 0 and kaw_slope != 0:\n",
    "                                model_left = LinearRegression().fit(np.log10(x[left_mask]).reshape(-1, 1), np.log10(y[left_mask]))\n",
    "                                model_right = LinearRegression().fit(np.log10(x[right_mask]).reshape(-1, 1), np.log10(y[right_mask]))\n",
    "                                \n",
    "                                r2_mhd = r2_score(np.log10(y[left_mask]),model_left.predict(np.log10(x[left_mask]).reshape(-1, 1)))\n",
    "                                r2_kaw = r2_score(np.log10(y[right_mask]),model_right.predict(np.log10(x[right_mask]).reshape(-1, 1)))\n",
    "                                \n",
    "                                plt.loglog(10**np.log10(x[left_mask]), 10**model_left.predict(np.log10(x[left_mask]).reshape(-1, 1)), color='blue', label = 'Slope MHD: ' + str(round(mhd_slope,3))+r', $R^2=$' +str(round(r2_mhd,3)))#, alpha = 0.01)  # Fitted left line\n",
    "                                plt.loglog(10**np.log10(x[right_mask]), 10**model_right.predict(np.log10(x[right_mask]).reshape(-1, 1)), color='orange', label ='Slope KAW: ' + str(round(kaw_slope,3))+r', $R^2=$' +str(round(r2_kaw,3)))#, alpha=0.01)  # Fitted right line\n",
    "                                #plt.axvline(x = fb, label='Calculated break')\n",
    "                                plt.axvline(x = theoretical_break_raw, label = r'$k_{\\perp}\\rho_i=1$', color = 'green')\n",
    "                            elif mhd_slope == 0:\n",
    "                                model_right = LinearRegression().fit(np.log10(x[right_mask]).reshape(-1, 1), np.log10(y[right_mask]))\n",
    "                                r2_kaw = r2_score(np.log10(y[right_mask]),model_right.predict(np.log10(x[right_mask]).reshape(-1, 1)))\n",
    "                                plt.loglog(10**np.log10(x[right_mask]), 10**model_right.predict(np.log10(x[right_mask]).reshape(-1, 1)), color='orange', label ='Slope KAW: ' + str(round(kaw_slope,3))+r', $R^2=$' +str(round(r2_kaw,3)))#, alpha=0.01)  # Fitted right line\n",
    "                               # plt.axvline(x = fb, label='Calculated break')\n",
    "                                plt.axvline(x = theoretical_break_raw, label = r'$k_{\\perp}\\rho_i=1$', color = 'green')\n",
    "                            elif kaw_slope == 0:\n",
    "\n",
    "                                model_left = LinearRegression().fit(np.log10(x[left_mask]).reshape(-1, 1), np.log10(y[left_mask]))\n",
    "                                r2_mhd = r2_score(np.log10(y[left_mask]),model_left.predict(np.log10(x[left_mask]).reshape(-1, 1)))\n",
    "\n",
    "                                plt.loglog(10**np.log10(x[left_mask]), 10**model_left.predict(np.log10(x[left_mask]).reshape(-1, 1)), color='orange', label ='Slope MHD: ' + str(round(mhd_slope,3))+r', $R^2=$' +str(round(r2_mhd,3)))#, alpha=0.01)  # Fitted right line\n",
    "                                #plt.axvline(x = fb, label='Calculated break')\n",
    "                                plt.axvline(x = theoretical_break_raw, label = r'$k_{\\perp}\\rho_i=1$', color = 'green')\n",
    "                            plt.xlabel('f [Hz]')\n",
    "                            plt.ylabel('PSD [T^2/Hz]')\n",
    "                            plt.title('PSD, L = ' +str(round(mean_R_value,3)) +', $Z_{mag} = $' +str(round(mean_Z_value,2)) +', |v| = ' +str(round(mean_v)) + ' m/s, sin(theta_vb) = ' +str(round(mean_sintheta,2))+', Temp. = ' +str(round(mean_temp*11606))+' K')\n",
    "                            plt.minorticks_on()\n",
    "                            plt.grid(True, which='minor', axis='both', linestyle=':', color='gray', alpha=0.75)\n",
    "                            plt.grid(True)\n",
    "                            plt.legend()\n",
    "                            plt.savefig(directory+'/PSD', facecolor = 'white')\n",
    "                            \n",
    "                            plt.close()\n",
    "                            plt.figure(figsize=(10, 6))\n",
    "\n",
    "                            try:\n",
    "                                \n",
    "                                if q_mhd == 100:\n",
    "                                    plt.loglog(q_kaw_freqs, q_kaw)\n",
    "                                    plt.axhline(y= np.mean(q_kaw), c='red',label = r'$q_{KAW} = $' + str(round(np.mean(q_kaw), 20)))\n",
    "                            except:\n",
    "                                pass\n",
    "                            try:\n",
    "                                \n",
    "                                if q_kaw == 100:\n",
    "                                    plt.loglog(q_mhd_freqs, q_mhd)\n",
    "                                    plt.axhline(y= np.mean(q_mhd), c='green',label = r'$q_{MHD} = $' + str(round(np.mean(q_mhd), 20)))\n",
    "                            except:\n",
    "                                pass\n",
    "                            try:\n",
    "                                len_q_mhd = len(q_mhd)\n",
    "                                len_q_kaw = len(q_kaw)\n",
    "                                \n",
    "                                plt.loglog(q_all_freqs, q_all)\n",
    "                                plt.axhline(y= np.mean(q_all), c='purple',label = r'$q = $' + str(round(np.mean(q_all), 20)))\n",
    "                                \n",
    "                                \n",
    "                                plt.loglog(q_kaw_freqs, q_kaw)\n",
    "                                plt.axhline(y= np.mean(q_kaw), c='red',label = r'$q_{KAW} = $' + str(round(np.mean(q_kaw), 20)))\n",
    "                                \n",
    "                                plt.loglog(q_mhd_freqs, q_mhd)\n",
    "                                plt.axhline(y= np.mean(q_mhd), c='green',label = r'$q_{MHD} = $' + str(round(np.mean(q_mhd), 20)))\n",
    "                            except:\n",
    "                                pass\n",
    "\n",
    "                            plt.xlabel('f [Hz]')\n",
    "                            plt.ylabel(r'$q [W/m^3]$')\n",
    "                            \n",
    "                            plt.title('Heating Rate Density, L = ' +str(round(mean_R_value,3)) +', $Z_{mag} = $' +str(round(mean_Z_value,2)) +' , |v| = '+str(round(mean_v)) + ' m/s, sin(theta_vb) = ' +str(round(mean_sintheta,2))+', Temp. = ' +str(round(mean_temp*11606))+' K')\n",
    "                            plt.minorticks_on()\n",
    "                            plt.grid(True, which='minor', axis='both', linestyle=':', color='gray', alpha=0.75)\n",
    "                            plt.grid(True)\n",
    "                            plt.legend()\n",
    "                            plt.savefig(directory+ '/q_plot', facecolor = 'white')\n",
    "                            plt.close()\n",
    "                            \n",
    "                            \n",
    "                            fig,ax = plt.subplots(4, figsize=(12, 9), sharex='all')\n",
    "                            delta_b_perp_mag = np.sqrt(interval_perp_x**2 + interval_perp_y**2 + interval_perp_z**2)\n",
    "                            norm_b_perp = delta_b_perp_mag/interval_mean_B_mag\n",
    "                            \n",
    "                            delta_v_perp_mag = np.sqrt(interval_v_perp_x**2+interval_v_perp_y**2+interval_v_perp_z**2)\n",
    "                            try:\n",
    "                                norm_v_perp = delta_v_perp_mag / v_Alfven\n",
    "                            except: \n",
    "                                print('mistmatch')\n",
    "                                t+=1\n",
    "                                plt.close()\n",
    "                                continue\n",
    "\n",
    "                            \n",
    "                            ax[0].scatter(interval_v_perp_index, norm_v_perp, label = 'normalized delta_v_perp')\n",
    "                            ax[0].scatter(interval_B_perp_index, norm_b_perp, label = 'normalized delta_b_perp')\n",
    "                            \n",
    "                            ax[1].scatter(interval_v_perp_index, interval_v_perp_x/v_Alfven)\n",
    "                            ax[1].scatter(interval_B_perp_index, interval_perp_x/interval_mean_B_mag) \n",
    "                                \n",
    "                            ax[2].scatter(interval_v_perp_index, interval_v_perp_y/v_Alfven)\n",
    "                            ax[2].scatter(interval_B_perp_index, interval_perp_y/interval_mean_B_mag)\n",
    "                            \n",
    "                            ax[3].scatter(interval_v_perp_index, interval_v_perp_z/v_Alfven)\n",
    "                            ax[3].scatter(interval_B_perp_index, interval_perp_z/interval_mean_B_mag)\n",
    "                            \n",
    "                                \n",
    "                            plt.xlabel('Time')\n",
    "                            #plt.ylabel(r'$q_{MHD} [W/m^3]$')\n",
    "                            ax[0].set_title('Delta_B_perp vs Delta_v_perp, L = ' +str(round(mean_R_value,3)) +', $Z_{mag} = $' +str(round(mean_Z_value,2)) +', |v| = ' +str(round(mean_v)) + ' m/s, sin(theta_vb) = ' +str(round(mean_sintheta,2))+', Temp. = ' +str(round(mean_temp*11606))+' K')\n",
    "                            #plt.minorticks_on()\n",
    "                            #plt.grid(True, which='minor', axis='both', linestyle=':', color='gray', alpha=0.75)\n",
    "                            #plt.grid(True)\n",
    "                            ax[0].legend()\n",
    "                            ax[0].set_ylabel('Magnitude')\n",
    "                            ax[1].set_ylabel('Perp X')\n",
    "                            ax[2].set_ylabel('Perp Y')\n",
    "                            ax[3].set_ylabel('Perp Z')\n",
    "\n",
    "                            plt.savefig(directory+'/variations', facecolor = 'white')\n",
    "                            plt.close()\n",
    "                            \n",
    "                            fig,ax = plt.subplots(4, figsize=(12, 9), sharex='all')\n",
    "                            \n",
    "                            window_size=1\n",
    "                            mean_perp_data = pd.DataFrame({'MEAN_BX_perp': [],\n",
    "                                    'MEAN_BY_perp': [],\n",
    "                                    'MEAN_BZ_perp' : [],\n",
    "                                    'MEAN_B_perp_mag' : [],\n",
    "                                    'MEAN_B_mean': []\n",
    "})\n",
    "                            try:\n",
    "                                interval_v_perp_index_no_na = delta_v_df['u_x_pert_perp'][start_index: end_index].dropna().index\n",
    "\n",
    "\n",
    "                                finish_datetime = (interval_v_perp_index_no_na[-1]\n",
    "                            - timedelta(minutes=np.floor(window_size/2)))\n",
    "                                for datetime_index in interval_v_perp_index_no_na:\n",
    "                                    start_datetime = datetime_index - timedelta(seconds = 30)\n",
    "                                    end_datetime = start_datetime + timedelta(seconds = 60)\n",
    "                                    mean_datetime_index = pd.DatetimeIndex([\n",
    "                                    (start_datetime + timedelta(seconds=30)).isoformat()\n",
    "                                    ])\n",
    "                                    temp_mean_Bx_perp = np.nanmean(interval_perp_x[np.where( (interval_B_perp_index >= start_datetime.isoformat()) & (interval_B_perp_index <= end_datetime.isoformat()) )] )\n",
    "                                    temp_mean_By_perp = np.nanmean(interval_perp_y[np.where( (interval_B_perp_index >= start_datetime.isoformat()) & (interval_B_perp_index <= end_datetime.isoformat()) )] )\n",
    "                                    temp_mean_Bz_perp = np.nanmean(interval_perp_z[np.where( (interval_B_perp_index >= start_datetime.isoformat()) & (interval_B_perp_index <= end_datetime.isoformat()) )] )\n",
    "                                    temp_mean_B_perp_mag = np.sqrt(temp_mean_Bx_perp**2+temp_mean_By_perp**2+temp_mean_Bz_perp**2)\n",
    "                                    temp_mean_B_Mean = np.nanmean(interval_mean_B_mag[np.where( (interval_B_perp_index >= start_datetime.isoformat()) & (interval_B_perp_index <= end_datetime.isoformat()) )] )\n",
    "\n",
    "                                    mean_array_to_concat = pd.DataFrame(\n",
    "                                    {'MEAN_BX_perp': temp_mean_Bx_perp,\n",
    "                                        'MEAN_BY_perp': temp_mean_By_perp,\n",
    "                                        'MEAN_BZ_perp' : temp_mean_Bz_perp,\n",
    "                                        'MEAN_B_perp_mag' : temp_mean_B_perp_mag,\n",
    "                                        'MEAN_B_mean': temp_mean_B_Mean\n",
    "                                        \n",
    "                                        }, index=mean_datetime_index)\n",
    "                                    mean_perp_data = pd.concat([mean_perp_data, mean_array_to_concat])\n",
    "                                \n",
    "                                    #if mean_datetime_index == finish_datetime:\n",
    "                                    #   break\n",
    "                                #mean_perp_df = mean_perp_df[mean_energy_data.index[0].isoformat(): \n",
    "                                #                        mean_energy_data.index[-1].isoformat()]\n",
    "                                #mean_perp_df = pd.concat([energy_df, mean_energy_data], axis=1)\n",
    "\n",
    "                                \n",
    "                                \n",
    "                                \n",
    "                                #delta_b_perp_mag = np.sqrt(interval_perp_x**2 + interval_perp_y**2 + interval_perp_z**2)\n",
    "                                #norm_b_perp = delta_b_perp_mag/interval_mean_B_mag\n",
    "                                \n",
    "                                delta_v_perp_mag = np.sqrt(interval_v_perp_x**2+interval_v_perp_y**2+interval_v_perp_z**2)\n",
    "                                \n",
    "                                \n",
    "                                norm_v_perp = delta_v_perp_mag / v_Alfven\n",
    "                                \n",
    "                                    \n",
    "                                \n",
    "                                \n",
    "                                ax[0].scatter(interval_v_perp_index, norm_v_perp, label = 'normalized delta_v_perp')\n",
    "                                ax[0].scatter(mean_perp_data.index, mean_perp_data['MEAN_B_perp_mag']/mean_perp_data['MEAN_B_mean'], label = 'normalized delta_b_perp',marker = '*')\n",
    "                                \n",
    "                                ax[1].scatter(interval_v_perp_index, interval_v_perp_x/v_Alfven)\n",
    "                                ax[1].scatter(mean_perp_data.index, mean_perp_data['MEAN_BX_perp']/mean_perp_data['MEAN_B_mean'],marker = '*') \n",
    "                                    \n",
    "                                ax[2].scatter(interval_v_perp_index, interval_v_perp_y/v_Alfven)\n",
    "                                ax[2].scatter(mean_perp_data.index, mean_perp_data['MEAN_BY_perp']/mean_perp_data['MEAN_B_mean'],marker = '*')\n",
    "                                \n",
    "                                ax[3].scatter(interval_v_perp_index, interval_v_perp_z/v_Alfven)\n",
    "                                ax[3].scatter(mean_perp_data.index, mean_perp_data['MEAN_BZ_perp']/mean_perp_data['MEAN_B_mean'],marker = '*')\n",
    "                                \n",
    "                                    \n",
    "                                plt.xlabel('Time')\n",
    "                                ax[0].set_ylabel('Magnitude')\n",
    "                                ax[1].set_ylabel('Perp X')\n",
    "                                ax[2].set_ylabel('Perp Y')\n",
    "                                ax[3].set_ylabel('Perp Z')\n",
    "\n",
    "                                #plt.ylabel(r'$q_{MHD} [W/m^3]$')\n",
    "                                ax[0].set_title('Delta_B_perp vs Delta_v_perp, L = ' +str(round(mean_R_value,3)) +', $Z_{mag} = $' +str(round(mean_Z_value,2)) +', |v| = ' +str(round(mean_v)) + ' m/s, sin(theta_vb) = ' +str(round(mean_sintheta,2))+', Temp. = ' +str(round(mean_temp*11606))+' K')\n",
    "                                #plt.minorticks_on()\n",
    "                                #plt.grid(True, which='minor', axis='both', linestyle=':', color='gray', alpha=0.75)\n",
    "                                #plt.grid(True)\n",
    "                                ax[0].legend()\n",
    "                                plt.savefig(directory+'/variations2', facecolor = 'white')\n",
    "                                plt.close()\n",
    "                                \n",
    "                                \n",
    "                                \n",
    "                                sorted_dfs_desc_R = interval_compression_df\n",
    "                                \n",
    "                                fig, ax = plt.subplots(4, figsize = (12,8),sharex='all')\n",
    "                                \n",
    "                                \n",
    "\n",
    "                                size = 20\n",
    "\n",
    "                                delta_rho_over_delta_v_perp = np.abs(sorted_dfs_desc_R['delta_density'])/sorted_dfs_desc_R['delta_v_perp_mag']\n",
    "                                v_p = np.sqrt(sorted_dfs_desc_R['v_Alfven']**2 + sorted_dfs_desc_R['v_S']**2)\n",
    "\n",
    "                                rho_over_vp = sorted_dfs_desc_R['MEAN_density']/v_p\n",
    "                                \n",
    "                                deltas_ratio = delta_rho_over_delta_v_perp/rho_over_vp\n",
    "\n",
    "                                delta_v_perp_over_v_p = sorted_dfs_desc_R['delta_v_perp_mag']/v_p\n",
    "\n",
    "                                delta_b_perp_over_b = sorted_dfs_desc_R['B_pert_perp_mag']/sorted_dfs_desc_R['MEAN_B']\n",
    "\n",
    "                                delta_b_par_over_b = sorted_dfs_desc_R['B_pert_par_mag']/sorted_dfs_desc_R['MEAN_B']\n",
    "\n",
    "\n",
    "                                ax[0].scatter(interval_compression_df_index,deltas_ratio,s=size)\n",
    "                                ax[0].axhline(y=1,color='red')\n",
    "\n",
    "                                ax[0].set_title(r'$\\frac{|\\delta \\rho|}{|\\delta v_{\\perp}|}/\\frac{\\rho}{v_p}$')\n",
    "                                \n",
    "                                \n",
    "                                \n",
    "\n",
    "                                ax[2].scatter(interval_compression_df_index, sorted_dfs_desc_R['v_S']/sorted_dfs_desc_R['v_Alfven'],s=size)\n",
    "                                ax[2].axhline(y=1,color='red')\n",
    "                                \n",
    "                                \n",
    "                                ax[1].scatter(interval_compression_df_index, sorted_dfs_desc_R['v_S'],s=size)\n",
    "                                \n",
    "                                \n",
    "                                ax[1].set_title(r'$v_S$')\n",
    "                                ax[2].set_title(r'$v_S/v_{A}$')\n",
    "\n",
    "                                ax[3].scatter(interval_compression_df_index, delta_b_perp_over_b, label = r'$\\delta B_{\\perp}/B$',s=size,alpha=0.25 )\n",
    "                                ax[3].scatter(interval_compression_df_index, delta_b_par_over_b, label = r'$\\delta B_{||}/B$',s=size,alpha=0.25)\n",
    "                                ax[3].scatter(interval_compression_df_index, delta_v_perp_over_v_p, c='k',label = r'$\\delta v_{\\perp}/v_p$',s=size*10, marker = 'x')\n",
    "                                \n",
    "\n",
    "                                ax[0].set_yscale('log')\n",
    "                                ax[1].set_yscale('log')\n",
    "                                ax[2].set_yscale('log')\n",
    "                                ax[3].set_yscale('log')\n",
    "\n",
    "\n",
    "                                ax[3].legend()\n",
    "                                \n",
    "                                \n",
    "\n",
    "                                plt.savefig(directory+'/compression', facecolor = 'white')\n",
    "\n",
    "                                plt.close()\n",
    "                                '''\n",
    "                                sorted_dfs_desc_R = interval_compression_df_2\n",
    "                                interval_compression_df_index = interval_compression_df_2.index\n",
    "                                \n",
    "                                fig, ax = plt.subplots(4, figsize = (12,8),sharex='all')\n",
    "                                \n",
    "                                \n",
    "                                \n",
    "                                \n",
    "                                size = 20\n",
    "                                \n",
    "                                print('here')\n",
    "\n",
    "                                delta_rho_over_delta_v_perp = np.abs(sorted_dfs_desc_R['delta_density'])/sorted_dfs_desc_R['delta_v_perp_mag']\n",
    "                                v_p = np.sqrt(sorted_dfs_desc_R['v_Alfven']**2 + sorted_dfs_desc_R['v_S']**2)\n",
    "\n",
    "                                rho_over_vp = sorted_dfs_desc_R['MEAN_density']/v_p\n",
    "                                \n",
    "                                deltas_ratio = delta_rho_over_delta_v_perp/rho_over_vp\n",
    "\n",
    "                                delta_v_perp_over_v_p = sorted_dfs_desc_R['delta_v_perp_mag']/v_p\n",
    "\n",
    "                                delta_b_perp_over_b = sorted_dfs_desc_R['B_pert_perp_mag']/sorted_dfs_desc_R['MEAN_B']\n",
    "\n",
    "                                delta_b_par_over_b = sorted_dfs_desc_R['B_pert_par_mag']/sorted_dfs_desc_R['MEAN_B']\n",
    "\n",
    "\n",
    "                                ax[0].scatter(interval_compression_df_index,deltas_ratio,s=size)\n",
    "                                ax[0].set_title(r'$\\frac{|\\delta \\rho|}{|\\delta v_{\\perp}|}/\\frac{\\rho}{v_p}$')\n",
    "                                \n",
    "                                \n",
    "                                \n",
    "\n",
    "                                ax[2].scatter(interval_compression_df_index, sorted_dfs_desc_R['v_S']/sorted_dfs_desc_R['v_Alfven'],s=size)\n",
    "                                \n",
    "                                \n",
    "                                ax[1].scatter(interval_compression_df_index, sorted_dfs_desc_R['v_S'],s=size)\n",
    "                                \n",
    "                                \n",
    "                                ax[1].set_title(r'$v_S$')\n",
    "                                ax[2].set_title(r'$v_S/v_{A}$')\n",
    "\n",
    "                                ax[3].scatter(interval_compression_df_index, delta_b_perp_over_b, label = r'$\\delta B_{\\perp}/B$',s=size,alpha=0.25 )\n",
    "                                ax[3].scatter(interval_compression_df_index, delta_b_par_over_b, label = r'$\\delta B_{||}/B$',s=size,alpha=0.25)\n",
    "                                ax[3].scatter(interval_compression_df_index, delta_v_perp_over_v_p, c='k',label = r'$\\delta v_{\\perp}/v_p$',s=size*10, marker = 'x')\n",
    "                                \n",
    "\n",
    "                                ax[0].set_yscale('log')\n",
    "                                ax[1].set_yscale('log')\n",
    "                                ax[2].set_yscale('log')\n",
    "                                ax[3].set_yscale('log')\n",
    "\n",
    "\n",
    "                                ax[3].legend()\n",
    "                                \n",
    "                                \n",
    "\n",
    "                                plt.savefig(directory+'/compression2', facecolor = 'white')\n",
    "\n",
    "                                plt.close()\n",
    "                                '''\n",
    "\n",
    "                            except:\n",
    "                                plt.close()\n",
    "                                t+=1\n",
    "                                pass\n",
    "                                \n",
    "                            \n",
    "                            \n",
    "                            t+=1\n",
    "\n",
    "        else:\n",
    "            continue\n",
    "        \n",
    "    time = pd.date_range(data_df.index[0].isoformat(),\n",
    "                        data_df.index[-1].isoformat(),\n",
    "                        periods=len(mean_q))\n",
    "\n",
    "          \n",
    "    q_data = pd.DataFrame({'q': mean_q,\n",
    "                            'q_kaw': mean_q_kaw,\n",
    "                            'q_mhd': mean_q_mhd,\n",
    "                            'mean_R': mean_R,\n",
    "                            'mean_Z': mean_z,\n",
    "                            'mean_density': mean_density_array,\n",
    "                            'mean_vphi': mean_vphi_array,\n",
    "                            'mean_b_perp' : mean_b_perp,\n",
    "                            'avg_times' : avg_times,\n",
    "                            'local_times': local_time_array,\n",
    "                            'kperps': mean_kperps,\n",
    "                            'mean_deltabperp3': mean_delta_bperp3_array,\n",
    "                            'sintheta': mean_sintheta_array,\n",
    "                            '|v|': mean_v_array,\n",
    "                            'freq_mhd': mean_freqs_array,\n",
    "                            'q_mean_whole_range': q_mean_whole_range\n",
    "                            \n",
    "                            },index=time)\n",
    "\n",
    "    plt.cla()\n",
    "    return q_data, q_mhd_slopes, q_kaw_slopes, breaks, gyros, rho_i_array, theta_array\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "614d6699",
   "metadata": {},
   "source": [
    "Reading in fits data..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1febf2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fits_data = pd.read_csv('/data/juno_spacecraft/data/FWD_FITS/JADE-I_forward_model_ion_v1/JADE-I_forward_model_ion_all_v1.csv', delimiter= ',')\n",
    "def convert_datetime(datetime_str):\n",
    "    # Remove the microseconds part\n",
    "    datetime_str_cleaned = datetime_str.split('.')[0]\n",
    "    # Convert to pandas datetime object\n",
    "    date_time = pd.to_datetime(datetime_str_cleaned, format='%Y-%jT%H:%M:%S')\n",
    "    # Format to the desired output\n",
    "    return pd.to_datetime(date_time.strftime('%Y-%m-%dT%H:%M:%S'))\n",
    "\n",
    "fits_data['DATETIME'] = fits_data['                \"UTC\"'].apply(convert_datetime)\n",
    "fits_data = fits_data.drop(columns='                \"UTC\"')\n",
    "\n",
    "fits_data = fits_data.set_index('DATETIME', drop=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1209918e",
   "metadata": {},
   "outputs": [],
   "source": [
    "saving_pickles = True\n",
    "time_res = '1s'\n",
    "mean_window = '4min'\n",
    "interval = 20 \n",
    "startOrbitNumber = 6\n",
    "endOrbitNumber =  54\n",
    "\n",
    "\n",
    "name_of_dir='slope_limits_20min_jsscorrected_psdcorrected'\n",
    "\n",
    "#mean_mag_data_files_dir = '/home/mtfranciscovich/Juno-codes/jss_reduced_inbound_1s_means_4min_pickles'  #This is the filename for each orbit's magdata means in JSS coordinates (Also R data)\n",
    "mean_mag_data_files_dir = '/home/mtfranciscovich/Juno-codes/means_4min_reduced_inbound_1s_pickles_unit_z_mag'\n",
    "mag_data_mag_frame_dir = '/home/mtfranciscovich/Juno-codes/reduced_inbound_1s_pickles' #This is the magdata in the magframe (Z_MAG data)\n",
    "v_perps_dir = '/home/mtfranciscovich/Juno-codes/test_fits_u_cart_means_4min' #This is the v_perp data (only necessary in case study)\n",
    "\n",
    "\n",
    "directory_to_store_q_pickles_parent = '/home/mtfranciscovich/Juno-codes/'+name_of_dir+'/'+str(interval)+'min_qs_fits_jss_keepcone_nointerp_pickles'\n",
    "directory_to_store_orbit_qs = directory_to_store_q_pickles_parent+'/orbit_qs'\n",
    "if not os.path.exists(directory_to_store_orbit_qs):\n",
    "    os.makedirs(directory_to_store_orbit_qs)\n",
    "    \n",
    "directory_to_store_q_pickles_extras_indexed = directory_to_store_q_pickles_parent+'/orbit_indexed'\n",
    "if not os.path.exists(directory_to_store_q_pickles_extras_indexed):\n",
    "    os.makedirs(directory_to_store_q_pickles_extras_indexed)\n",
    "    \n",
    "directory_to_store_q_pickles_extras_not_indexed = directory_to_store_q_pickles_parent+'/orbit_not_indexed'\n",
    "if not os.path.exists(directory_to_store_q_pickles_extras_not_indexed):\n",
    "    os.makedirs(directory_to_store_q_pickles_extras_not_indexed)\n",
    "\n",
    "\n",
    "do_case_study = True\n",
    "case_study_parent = '/home/mtfranciscovich/Juno-codes/'+name_of_dir+'/test2_case_study_images_fits'\n",
    "if do_case_study:\n",
    "    if not os.path.exists(case_study_parent):\n",
    "        os.makedirs(case_study_parent)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for i in range(startOrbitNumber, endOrbitNumber+1):\n",
    "    case_study_dir = case_study_parent\n",
    "\n",
    "    print('Grabbing Orbit #' +str(i)+' Mag Data...')\n",
    "    #filename = mean_mag_data_files_dir+'/reduced_orbit_' +str(i)+'_'+str(mean_window)+ '_means_'  +str(time_res) +'.pkl' \n",
    "    filename = mean_mag_data_files_dir+'/reduced_orbit_' + str(i) +'_1s.pkl'\n",
    "    picklefile = open(filename,'rb')\n",
    "    orbit_means = pickle.load(picklefile)\n",
    "    #print(orbit_means.columns)\n",
    "    #continue\n",
    "    filename = mag_data_mag_frame_dir+'/reduced_orbit_' +str(i) +'_1s.pkl' #This is the magdata in the magframe (Z_MAG data)\n",
    "    picklefile = open(filename,'rb')\n",
    "    mag_data_mag_frame = pickle.load(picklefile)\n",
    "    z_mag_info = mag_data_mag_frame['Z_MAG'] #The Z_mag data from the mag frame data file\n",
    "    R_info = mag_data_mag_frame['R']\n",
    "    \n",
    "    \n",
    "    \n",
    "    print('Grabbing Orbit #' +str(i)+' v_perps...')\n",
    "    filename = v_perps_dir+'/u_cart_means_4min_orbit_' + str(i)+'.pkl' \n",
    "    picklefile = open(filename,'rb')\n",
    "    orbit_v_perps = pickle.load(picklefile)\n",
    "    \n",
    "    \n",
    "        \n",
    "\n",
    "    print('Combining input data dfs...')\n",
    "    all_dates = orbit_means.index.union(fits_data.index)\n",
    "    reindexed_orbit_means = orbit_means.reindex(all_dates)\n",
    "    reindexed_fits_data = fits_data.reindex(all_dates)\n",
    "    combined_current = reindexed_orbit_means.combine_first(reindexed_fits_data)\n",
    "    beginning_of_orbit_data = orbit_means.index[0]\n",
    "    end_of_orbit_data = orbit_means.index[-1]\n",
    "    combined_updated_for_orbit = combined_current[beginning_of_orbit_data:end_of_orbit_data]\n",
    "    combined_updated_for_orbit['Z_MAG'] = z_mag_info\n",
    "    \n",
    "    print('Grabbing compression data dfs for case study...')\n",
    "    filename = '/home/mtfranciscovich/Juno-codes/compression_dfs_by_orbit/compression_df_orbit_'+str(i)+'.pkl'\n",
    "    picklefile = open(filename,'rb')\n",
    "    compression_df = pickle.load(picklefile)\n",
    "    \n",
    "    if do_case_study:  \n",
    "\n",
    "        \n",
    "    \n",
    "        print('Calculating q...')\n",
    "        q_datas = _get_q(do_case_study, case_study_dir, compression_df,True,True, combined_updated_for_orbit['Z_MAG'],orbit_v_perps,1.2e-2, 3e-1, 1e-2, 1.5e-1, combined_updated_for_orbit, combined_updated_for_orbit, interval, 1, False, True, False, i, 10, True,False, False)\n",
    "        #                case_study, case_directory, compression_df,one_equation, theo_break, z_mag_df,delta_v_df,minf_index, maxf_index, minf, maxf, data_df, part_df, interval, dt, filter_magnitude, fits, moments,orbit_number, case_chance, test,empirical =False, remove_coi = False,acceptable_freqs_min = 2e-2, acceptable_freqs_max = 8e-2\n",
    "        q_cleaned = q_datas[0][q_datas[0]['q'] != -1]\n",
    "    else: \n",
    "        print('Calculating q...')\n",
    "        q_datas = _get_q(do_case_study,case_study_dir, compression_df,True,True, combined_updated_for_orbit['Z_MAG'],orbit_v_perps,1.2e-2, 3e-1, 1e-2, 1.5e-1, combined_updated_for_orbit, combined_updated_for_orbit, interval, 1, False, True, False, i, 0, True,False, False)\n",
    "        q_cleaned = q_datas[0][q_datas[0]['q'] != -1]\n",
    "    \n",
    "    if saving_pickles:\n",
    "        q_datas[0].to_pickle(directory_to_store_orbit_qs+'/q_array_orbit_' +str(i)+'.pkl')\n",
    "        df_extras_indexed = pd.DataFrame({'mhd_slopes': q_datas[1],\n",
    "                                'kinetic_slopes': q_datas[2],\n",
    "                                'R': q_datas[0]['mean_R'],\n",
    "                                'Z': q_datas[0]['mean_Z'],\n",
    "                                'local_times': q_datas[0]['local_times']},index = q_datas[0].index)\n",
    "        df_extras_indexed.to_pickle(directory_to_store_q_pickles_extras_indexed+'/extras_indexed_orbit_' +str(i)+'.pkl')\n",
    "\n",
    "        df_extras_not_indexed = pd.DataFrame({'breaks': q_datas[3],\n",
    "                                'gyros': q_datas[4],\n",
    "                                'thetas': q_datas[6]})\n",
    "\n",
    "\n",
    "        df_extras_not_indexed.to_pickle(directory_to_store_q_pickles_extras_not_indexed+'/extras_not_indexed_orbit_' +str(i)+'.pkl')\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "649006b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(q_datas[1]))\n",
    "\n",
    "print(len(q_datas[2]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d13cc5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f4d4e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
